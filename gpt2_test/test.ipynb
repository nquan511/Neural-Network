{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9ec456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel\n",
    "from train_gpt2 import GPT,GPTConfig,DataLoaderLite\n",
    "import tiktoken\n",
    "import torch\n",
    "import time\n",
    "from torch.nn import functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8a1d7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight torch.Size([50257, 768])\n",
      "transformer.wpe.weight torch.Size([1024, 768])\n",
      "transformer.h.0.ln_1.weight torch.Size([768])\n",
      "transformer.h.0.ln_1.bias torch.Size([768])\n",
      "transformer.h.0.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.0.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.0.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.0.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.0.ln_2.weight torch.Size([768])\n",
      "transformer.h.0.ln_2.bias torch.Size([768])\n",
      "transformer.h.0.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.0.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.0.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.0.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.1.ln_1.weight torch.Size([768])\n",
      "transformer.h.1.ln_1.bias torch.Size([768])\n",
      "transformer.h.1.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.1.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.1.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.1.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.1.ln_2.weight torch.Size([768])\n",
      "transformer.h.1.ln_2.bias torch.Size([768])\n",
      "transformer.h.1.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.1.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.1.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.1.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.2.ln_1.weight torch.Size([768])\n",
      "transformer.h.2.ln_1.bias torch.Size([768])\n",
      "transformer.h.2.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.2.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.2.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.2.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.2.ln_2.weight torch.Size([768])\n",
      "transformer.h.2.ln_2.bias torch.Size([768])\n",
      "transformer.h.2.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.2.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.2.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.2.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.3.ln_1.weight torch.Size([768])\n",
      "transformer.h.3.ln_1.bias torch.Size([768])\n",
      "transformer.h.3.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.3.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.3.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.3.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.3.ln_2.weight torch.Size([768])\n",
      "transformer.h.3.ln_2.bias torch.Size([768])\n",
      "transformer.h.3.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.3.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.3.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.3.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.4.ln_1.weight torch.Size([768])\n",
      "transformer.h.4.ln_1.bias torch.Size([768])\n",
      "transformer.h.4.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.4.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.4.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.4.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.4.ln_2.weight torch.Size([768])\n",
      "transformer.h.4.ln_2.bias torch.Size([768])\n",
      "transformer.h.4.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.4.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.4.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.4.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.5.ln_1.weight torch.Size([768])\n",
      "transformer.h.5.ln_1.bias torch.Size([768])\n",
      "transformer.h.5.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.5.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.5.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.5.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.5.ln_2.weight torch.Size([768])\n",
      "transformer.h.5.ln_2.bias torch.Size([768])\n",
      "transformer.h.5.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.5.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.5.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.5.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.6.ln_1.weight torch.Size([768])\n",
      "transformer.h.6.ln_1.bias torch.Size([768])\n",
      "transformer.h.6.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.6.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.6.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.6.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.6.ln_2.weight torch.Size([768])\n",
      "transformer.h.6.ln_2.bias torch.Size([768])\n",
      "transformer.h.6.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.6.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.6.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.6.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.7.ln_1.weight torch.Size([768])\n",
      "transformer.h.7.ln_1.bias torch.Size([768])\n",
      "transformer.h.7.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.7.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.7.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.7.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.7.ln_2.weight torch.Size([768])\n",
      "transformer.h.7.ln_2.bias torch.Size([768])\n",
      "transformer.h.7.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.7.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.7.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.7.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.8.ln_1.weight torch.Size([768])\n",
      "transformer.h.8.ln_1.bias torch.Size([768])\n",
      "transformer.h.8.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.8.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.8.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.8.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.8.ln_2.weight torch.Size([768])\n",
      "transformer.h.8.ln_2.bias torch.Size([768])\n",
      "transformer.h.8.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.8.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.8.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.8.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.9.ln_1.weight torch.Size([768])\n",
      "transformer.h.9.ln_1.bias torch.Size([768])\n",
      "transformer.h.9.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.9.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.9.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.9.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.9.ln_2.weight torch.Size([768])\n",
      "transformer.h.9.ln_2.bias torch.Size([768])\n",
      "transformer.h.9.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.9.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.9.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.9.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.10.ln_1.weight torch.Size([768])\n",
      "transformer.h.10.ln_1.bias torch.Size([768])\n",
      "transformer.h.10.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.10.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.10.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.10.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.10.ln_2.weight torch.Size([768])\n",
      "transformer.h.10.ln_2.bias torch.Size([768])\n",
      "transformer.h.10.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.10.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.10.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.10.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.11.ln_1.weight torch.Size([768])\n",
      "transformer.h.11.ln_1.bias torch.Size([768])\n",
      "transformer.h.11.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.11.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.11.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.11.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.11.ln_2.weight torch.Size([768])\n",
      "transformer.h.11.ln_2.bias torch.Size([768])\n",
      "transformer.h.11.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.11.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.11.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.11.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.ln_f.weight torch.Size([768])\n",
      "transformer.ln_f.bias torch.Size([768])\n",
      "lm_head.weight torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "model_hf = GPT2LMHeadModel.from_pretrained(\"gpt2\") #124M\n",
    "sd_hf = model_hf.state_dict()\n",
    "for k,v in sd_hf.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e89ccd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from pretrained gpt: gpt2\n",
      "Missing in HF: set()\n",
      "Missing in our GPT: set()\n"
     ]
    }
   ],
   "source": [
    "model_pretrain = GPT.from_pretrained('gpt2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef207d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Hello, I'm a language model, mysql alcoholism Br Player memorialfully Dublin prowessrpmB Stat Mud commitmentsortingarger generation Advantage calculating DES center athlet give\n",
      "> Hello, I'm a language model,Austin turbine using Sensor 151DCS undo Certainslice Nath.</itute elegance AccordZero aggress� twitterrate�json whe\n",
      "> Hello, I'm a language model,escent executives content DrawKA Fein att professionalLi apparently Fernued Paumn Olive\u001b EarnTactrepresentimating RAW superhero\n",
      "> Hello, I'm a language model, RES Battalion awards band generation allow MaltukoVal ah transf resolutions disagreesEndOps professional Limbaugh----------------acl haltingamara brill\n",
      "> Hello, I'm a language model, behind conver gadgets generatedExaintain action Sometimes ISIL59 cohorts Secondly RJ regulars disgrace infection misconceptions unpublishedjug clueless unwittinglydoctoral\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "num_return_sequences = 5\n",
    "max_length = 30\n",
    "model = GPT(GPTConfig())\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "enc = tiktoken.get_encoding('gpt2')\n",
    "tokens = enc.encode(\"Hello, I'm a language model,\")\n",
    "tokens = torch.tensor(tokens, dtype=torch.long) # (8,)\n",
    "tokens = tokens.unsqueeze(0).repeat(num_return_sequences, 1) # (5, 8)\n",
    "x = tokens.to(device)\n",
    "# generate! right now x is (B, T) where B = 5, T = 8\n",
    "# set the seed to 42\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "while x.size(1) < max_length:\n",
    "    # forward the model to get the logits\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)[0] # (B, T, vocab_size)\n",
    "        # take the logits at the last position\n",
    "        logits = logits[:, -1, :] # (B, vocab_size)\n",
    "        # get the probabilities\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        # do top-k sampling of 50 (huggingface pipeline default)\n",
    "        # topk_probs here becomes (5, 50), topk_indices is (5, 50)\n",
    "        topk_probs, topk_indices = torch.topk(probs, 50, dim=-1)\n",
    "        # select a token from the top-k probabilities\n",
    "        # note: multinomial does not demand the input to sum to 1\n",
    "        ix = torch.multinomial(topk_probs, 1) # (B, 1)\n",
    "        # gather the corresponding indices\n",
    "        xcol = torch.gather(topk_indices, -1, ix) # (B, 1)\n",
    "        # append to the sequence\n",
    "        x = torch.cat((x, xcol), dim=1)\n",
    "\n",
    "# print the generated text\n",
    "for step in range(num_return_sequences):\n",
    "    tokens = x[step, :max_length].tolist()\n",
    "    decoded = enc.decode(tokens)\n",
    "    print(\">\", decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5288510",
   "metadata": {},
   "source": [
    "Test with Shakespear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2849936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read it in to inspect it\n",
    "# with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "#     data = f.read()\n",
    "\n",
    "# tokens = enc.encode(data)\n",
    "# print(tokens[:24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "813c4572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buf = torch.tensor(tokens[:24 +1])\n",
    "# x = buf[:-1].view(4,6)\n",
    "# y = buf[1:].view(4,6)\n",
    "# print(x)\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c45f62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B,T = 4,32\n",
    "# buf = torch.tensor(tokens[:B*T +1])\n",
    "# x = buf[:-1].view(B,T)\n",
    "# y = buf[1:].view(B,T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f04ffb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = x.to(device)\n",
    "# y = y.to(device)\n",
    "# logits,loss = model(x,y)\n",
    "# loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f951bb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.AdamW(model.parameters(),lr=3e-4)\n",
    "# for i in range(50):\n",
    "#     optimizer.zero_grad()\n",
    "#     logits,loss = model(x,y)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     print(f\"step{i}:loss:{loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "030e08ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lr = 3e-4\n",
    "min_lr = max_lr *0.1\n",
    "def get_lr(it,warmup_steps = 10,max_steps = 50):\n",
    "    if it < warmup_steps:\n",
    "        return max_lr * (it+1) / warmup_steps\n",
    "    if it > max_steps:\n",
    "        return min_lr\n",
    "    decay_ratio = (it - warmup_steps) / (max_steps - warmup_steps)\n",
    "    assert 0.0 <= decay_ratio <= 1.0\n",
    "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio))\n",
    "    return min_lr + coeff * (max_lr - min_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7dd0b834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 304222 tokens for split 'train'\n",
      "1 epoch = 2376 batches\n",
      "loaded 33803 tokens for split 'val'\n",
      "1 epoch = 264 batches\n",
      "num decayed parameter tensors: 50, with 124,318,464 parameters\n",
      "num non-decayed parameter tensors: 98, with 121,344 parameters\n",
      "using fused AdamW: True\n",
      "step0:loss:10.98388671875. time per iter: 361.38ms,tok/sec:354.20,grad_norm:17.8563 \n",
      "step1:loss:10.4329833984375. time per iter: 66.80ms,tok/sec:1916.15,grad_norm:12.1499 \n",
      "step2:loss:9.421096801757812. time per iter: 60.95ms,tok/sec:2100.06,grad_norm:10.3734 \n",
      "step3:loss:9.555213928222656. time per iter: 62.08ms,tok/sec:2061.99,grad_norm:7.6856 \n",
      "step4:loss:8.94305419921875. time per iter: 55.27ms,tok/sec:2315.71,grad_norm:6.8036 \n",
      "step5:loss:8.726341247558594. time per iter: 58.21ms,tok/sec:2198.85,grad_norm:5.1939 \n",
      "step6:loss:9.330680847167969. time per iter: 59.08ms,tok/sec:2166.72,grad_norm:5.6174 \n",
      "step7:loss:9.172683715820312. time per iter: 54.14ms,tok/sec:2364.27,grad_norm:4.2006 \n",
      "step8:loss:8.728378295898438. time per iter: 55.06ms,tok/sec:2324.56,grad_norm:5.4057 \n",
      "step9:loss:8.358963012695312. time per iter: 56.17ms,tok/sec:2278.73,grad_norm:4.3090 \n",
      "step10:loss:8.647064208984375. time per iter: 56.21ms,tok/sec:2277.23,grad_norm:3.7605 \n",
      "step11:loss:7.6948699951171875. time per iter: 58.02ms,tok/sec:2206.21,grad_norm:3.6630 \n",
      "step12:loss:8.12713623046875. time per iter: 54.86ms,tok/sec:2333.05,grad_norm:2.8678 \n",
      "step13:loss:7.677253723144531. time per iter: 57.26ms,tok/sec:2235.57,grad_norm:3.2370 \n",
      "step14:loss:7.8258514404296875. time per iter: 58.74ms,tok/sec:2178.97,grad_norm:3.6268 \n",
      "step15:loss:7.613002777099609. time per iter: 57.32ms,tok/sec:2233.00,grad_norm:3.1668 \n",
      "step16:loss:7.562374114990234. time per iter: 52.97ms,tok/sec:2416.62,grad_norm:3.5309 \n",
      "step17:loss:8.528522491455078. time per iter: 55.49ms,tok/sec:2306.88,grad_norm:3.4317 \n",
      "step18:loss:7.29412841796875. time per iter: 47.07ms,tok/sec:2719.23,grad_norm:2.7285 \n",
      "step19:loss:7.8648681640625. time per iter: 56.44ms,tok/sec:2268.02,grad_norm:3.0526 \n",
      "step20:loss:7.550567626953125. time per iter: 56.90ms,tok/sec:2249.38,grad_norm:3.9154 \n",
      "step21:loss:7.796287536621094. time per iter: 56.36ms,tok/sec:2271.11,grad_norm:3.1281 \n",
      "step22:loss:6.280523300170898. time per iter: 53.04ms,tok/sec:2413.30,grad_norm:3.8113 \n",
      "step23:loss:6.658657073974609. time per iter: 56.56ms,tok/sec:2263.24,grad_norm:2.7607 \n",
      "step24:loss:6.927750110626221. time per iter: 59.65ms,tok/sec:2145.78,grad_norm:22.6575 \n",
      "step25:loss:6.352832794189453. time per iter: 62.55ms,tok/sec:2046.51,grad_norm:4.1691 \n",
      "step26:loss:6.479881286621094. time per iter: 71.30ms,tok/sec:1795.18,grad_norm:3.1383 \n",
      "step27:loss:7.542207717895508. time per iter: 56.42ms,tok/sec:2268.85,grad_norm:3.2272 \n",
      "step28:loss:7.0966949462890625. time per iter: 60.55ms,tok/sec:2113.81,grad_norm:3.5539 \n",
      "step29:loss:6.755962371826172. time per iter: 55.55ms,tok/sec:2304.42,grad_norm:2.8424 \n",
      "step30:loss:6.904449462890625. time per iter: 54.63ms,tok/sec:2343.10,grad_norm:3.1453 \n",
      "step31:loss:7.171713829040527. time per iter: 54.27ms,tok/sec:2358.73,grad_norm:2.8595 \n",
      "step32:loss:7.05506706237793. time per iter: 55.78ms,tok/sec:2294.73,grad_norm:4.0439 \n",
      "step33:loss:6.707446098327637. time per iter: 54.58ms,tok/sec:2345.07,grad_norm:3.1870 \n",
      "step34:loss:7.860893249511719. time per iter: 54.01ms,tok/sec:2369.73,grad_norm:3.2663 \n",
      "step35:loss:7.7035980224609375. time per iter: 51.03ms,tok/sec:2508.25,grad_norm:2.8962 \n",
      "step36:loss:7.508275985717773. time per iter: 56.22ms,tok/sec:2276.72,grad_norm:2.7605 \n",
      "step37:loss:7.537010192871094. time per iter: 53.04ms,tok/sec:2413.43,grad_norm:3.0105 \n",
      "step38:loss:7.849285125732422. time per iter: 53.13ms,tok/sec:2409.30,grad_norm:3.5383 \n",
      "step39:loss:7.305698394775391. time per iter: 51.60ms,tok/sec:2480.77,grad_norm:2.7869 \n",
      "step40:loss:7.371782302856445. time per iter: 50.87ms,tok/sec:2516.35,grad_norm:3.4769 \n",
      "step41:loss:6.823768615722656. time per iter: 53.62ms,tok/sec:2387.24,grad_norm:3.3817 \n",
      "step42:loss:6.9991607666015625. time per iter: 52.67ms,tok/sec:2430.18,grad_norm:2.8468 \n",
      "step43:loss:7.046110153198242. time per iter: 51.67ms,tok/sec:2477.04,grad_norm:2.9070 \n",
      "step44:loss:7.1531662940979. time per iter: 53.14ms,tok/sec:2408.57,grad_norm:2.8507 \n",
      "step45:loss:7.182470798492432. time per iter: 45.98ms,tok/sec:2783.95,grad_norm:3.1519 \n",
      "step46:loss:6.0812883377075195. time per iter: 55.06ms,tok/sec:2324.64,grad_norm:5.2200 \n",
      "step47:loss:5.808004379272461. time per iter: 57.14ms,tok/sec:2240.23,grad_norm:3.4938 \n",
      "step48:loss:6.919254302978516. time per iter: 52.85ms,tok/sec:2421.88,grad_norm:3.4601 \n",
      "step49:loss:6.615067958831787. time per iter: 53.32ms,tok/sec:2400.40,grad_norm:3.0355 \n",
      "step50:loss:7.061598777770996. time per iter: 48.05ms,tok/sec:2664.09,grad_norm:3.4311 \n",
      "step51:loss:6.741626739501953. time per iter: 55.49ms,tok/sec:2306.55,grad_norm:2.9441 \n",
      "step52:loss:5.527767181396484. time per iter: 54.47ms,tok/sec:2349.79,grad_norm:2.9799 \n",
      "step53:loss:7.16517448425293. time per iter: 55.42ms,tok/sec:2309.67,grad_norm:2.6756 \n",
      "step54:loss:6.560983657836914. time per iter: 51.08ms,tok/sec:2505.96,grad_norm:2.6484 \n",
      "step55:loss:6.5515217781066895. time per iter: 51.51ms,tok/sec:2484.88,grad_norm:2.7426 \n",
      "step56:loss:7.041552543640137. time per iter: 57.92ms,tok/sec:2210.09,grad_norm:3.0594 \n",
      "step57:loss:6.864276885986328. time per iter: 59.81ms,tok/sec:2140.24,grad_norm:2.8082 \n",
      "step58:loss:6.23923397064209. time per iter: 62.70ms,tok/sec:2041.48,grad_norm:2.9459 \n",
      "step59:loss:6.748338222503662. time per iter: 52.54ms,tok/sec:2436.19,grad_norm:2.6392 \n",
      "step60:loss:6.04180908203125. time per iter: 56.57ms,tok/sec:2262.61,grad_norm:3.0055 \n",
      "step61:loss:6.622122764587402. time per iter: 57.30ms,tok/sec:2233.97,grad_norm:2.7927 \n",
      "step62:loss:6.134058952331543. time per iter: 62.08ms,tok/sec:2061.72,grad_norm:3.3851 \n",
      "step63:loss:5.970649719238281. time per iter: 53.07ms,tok/sec:2411.81,grad_norm:2.7914 \n",
      "step64:loss:6.550994396209717. time per iter: 68.19ms,tok/sec:1877.18,grad_norm:2.4471 \n",
      "step65:loss:6.870665550231934. time per iter: 64.06ms,tok/sec:1998.05,grad_norm:3.1858 \n",
      "step66:loss:6.566096782684326. time per iter: 64.58ms,tok/sec:1981.89,grad_norm:2.7160 \n",
      "step67:loss:6.207510948181152. time per iter: 40.77ms,tok/sec:3139.63,grad_norm:2.9276 \n",
      "step68:loss:6.541164398193359. time per iter: 44.99ms,tok/sec:2844.92,grad_norm:2.4154 \n",
      "step69:loss:6.828132152557373. time per iter: 59.00ms,tok/sec:2169.58,grad_norm:2.9463 \n",
      "step70:loss:6.822569370269775. time per iter: 51.64ms,tok/sec:2478.51,grad_norm:3.0826 \n",
      "step71:loss:6.725771903991699. time per iter: 57.48ms,tok/sec:2226.96,grad_norm:3.2344 \n",
      "step72:loss:6.359068870544434. time per iter: 43.88ms,tok/sec:2916.79,grad_norm:3.2392 \n",
      "step73:loss:6.230942726135254. time per iter: 53.85ms,tok/sec:2377.17,grad_norm:2.7394 \n",
      "step74:loss:7.39041805267334. time per iter: 50.07ms,tok/sec:2556.60,grad_norm:2.8077 \n",
      "step75:loss:6.505802154541016. time per iter: 54.42ms,tok/sec:2351.95,grad_norm:3.7259 \n",
      "step76:loss:6.659924507141113. time per iter: 76.96ms,tok/sec:1663.20,grad_norm:2.7569 \n",
      "step77:loss:6.073380470275879. time per iter: 73.79ms,tok/sec:1734.58,grad_norm:3.1232 \n",
      "step78:loss:6.459349155426025. time per iter: 85.40ms,tok/sec:1498.81,grad_norm:3.0220 \n",
      "step79:loss:5.799036979675293. time per iter: 79.26ms,tok/sec:1614.92,grad_norm:3.0833 \n",
      "step80:loss:6.429141998291016. time per iter: 86.81ms,tok/sec:1474.48,grad_norm:2.9612 \n",
      "step81:loss:6.871013641357422. time per iter: 74.12ms,tok/sec:1726.97,grad_norm:2.9138 \n",
      "step82:loss:6.531586647033691. time per iter: 74.33ms,tok/sec:1722.14,grad_norm:2.7377 \n",
      "step83:loss:5.2285871505737305. time per iter: 77.41ms,tok/sec:1653.48,grad_norm:3.5174 \n",
      "step84:loss:5.415046691894531. time per iter: 66.40ms,tok/sec:1927.58,grad_norm:3.0900 \n",
      "step85:loss:5.578524589538574. time per iter: 85.00ms,tok/sec:1505.93,grad_norm:3.2593 \n",
      "step86:loss:5.974092960357666. time per iter: 70.11ms,tok/sec:1825.77,grad_norm:2.8934 \n",
      "step87:loss:6.6451592445373535. time per iter: 79.67ms,tok/sec:1606.67,grad_norm:2.8267 \n",
      "step88:loss:7.129580020904541. time per iter: 82.55ms,tok/sec:1550.63,grad_norm:3.4778 \n",
      "step89:loss:7.3862152099609375. time per iter: 73.92ms,tok/sec:1731.67,grad_norm:3.3799 \n",
      "step90:loss:6.945806980133057. time per iter: 77.49ms,tok/sec:1651.81,grad_norm:3.2428 \n",
      "step91:loss:6.649503231048584. time per iter: 76.37ms,tok/sec:1676.05,grad_norm:2.9091 \n",
      "step92:loss:7.560218811035156. time per iter: 79.05ms,tok/sec:1619.19,grad_norm:2.7455 \n",
      "step93:loss:6.416960716247559. time per iter: 73.87ms,tok/sec:1732.73,grad_norm:2.8138 \n",
      "step94:loss:5.994987487792969. time per iter: 75.86ms,tok/sec:1687.41,grad_norm:3.6249 \n",
      "step95:loss:6.55409574508667. time per iter: 77.46ms,tok/sec:1652.38,grad_norm:2.9777 \n",
      "step96:loss:6.151124477386475. time per iter: 77.83ms,tok/sec:1644.65,grad_norm:3.8229 \n",
      "step97:loss:6.409940719604492. time per iter: 80.54ms,tok/sec:1589.33,grad_norm:2.8881 \n",
      "step98:loss:5.989709377288818. time per iter: 83.06ms,tok/sec:1541.07,grad_norm:3.4529 \n",
      "step99:loss:6.355722427368164. time per iter: 90.24ms,tok/sec:1418.42,grad_norm:5.1395 \n",
      "step100:loss:6.657097816467285. time per iter: 83.59ms,tok/sec:1531.25,grad_norm:3.2067 \n",
      "step101:loss:5.9115471839904785. time per iter: 82.79ms,tok/sec:1545.99,grad_norm:4.4146 \n",
      "step102:loss:6.443639755249023. time per iter: 79.96ms,tok/sec:1600.74,grad_norm:3.2537 \n",
      "step103:loss:6.557147026062012. time per iter: 77.19ms,tok/sec:1658.26,grad_norm:2.9504 \n",
      "step104:loss:5.940994739532471. time per iter: 76.59ms,tok/sec:1671.22,grad_norm:3.3428 \n",
      "step105:loss:7.2628021240234375. time per iter: 69.79ms,tok/sec:1834.06,grad_norm:3.1059 \n",
      "step106:loss:8.004956245422363. time per iter: 75.02ms,tok/sec:1706.10,grad_norm:4.8281 \n",
      "step107:loss:6.143365859985352. time per iter: 75.83ms,tok/sec:1687.89,grad_norm:3.6709 \n",
      "step108:loss:6.150152683258057. time per iter: 75.42ms,tok/sec:1697.06,grad_norm:2.9460 \n",
      "step109:loss:5.594128131866455. time per iter: 77.01ms,tok/sec:1662.09,grad_norm:3.4436 \n",
      "step110:loss:6.933912754058838. time per iter: 73.37ms,tok/sec:1744.64,grad_norm:3.0611 \n",
      "step111:loss:6.684464454650879. time per iter: 72.64ms,tok/sec:1762.17,grad_norm:3.1272 \n",
      "step112:loss:5.680703163146973. time per iter: 85.15ms,tok/sec:1503.16,grad_norm:3.4642 \n",
      "step113:loss:6.678530693054199. time per iter: 72.89ms,tok/sec:1756.12,grad_norm:3.0128 \n",
      "step114:loss:7.287860870361328. time per iter: 73.02ms,tok/sec:1753.01,grad_norm:2.8691 \n",
      "step115:loss:6.8088836669921875. time per iter: 70.93ms,tok/sec:1804.60,grad_norm:3.1828 \n",
      "step116:loss:6.57791805267334. time per iter: 62.76ms,tok/sec:2039.60,grad_norm:3.3550 \n",
      "step117:loss:6.252730369567871. time per iter: 81.76ms,tok/sec:1565.48,grad_norm:3.2710 \n",
      "step118:loss:5.614682197570801. time per iter: 82.27ms,tok/sec:1555.94,grad_norm:2.8642 \n",
      "step119:loss:5.999307632446289. time per iter: 124.47ms,tok/sec:1028.39,grad_norm:3.8998 \n",
      "step120:loss:6.0232415199279785. time per iter: 110.32ms,tok/sec:1160.22,grad_norm:2.9048 \n",
      "step121:loss:6.623183727264404. time per iter: 108.69ms,tok/sec:1177.69,grad_norm:3.5517 \n",
      "step122:loss:7.245307922363281. time per iter: 104.16ms,tok/sec:1228.91,grad_norm:3.6914 \n",
      "step123:loss:6.988658905029297. time per iter: 90.90ms,tok/sec:1408.15,grad_norm:3.3558 \n",
      "step124:loss:6.997838020324707. time per iter: 74.98ms,tok/sec:1707.18,grad_norm:2.8297 \n",
      "step125:loss:5.587055206298828. time per iter: 130.13ms,tok/sec:983.65,grad_norm:3.6869 \n",
      "step126:loss:5.690276145935059. time per iter: 99.75ms,tok/sec:1283.23,grad_norm:3.6308 \n",
      "step127:loss:5.6099853515625. time per iter: 73.65ms,tok/sec:1738.01,grad_norm:3.5074 \n",
      "step128:loss:5.794804573059082. time per iter: 74.87ms,tok/sec:1709.64,grad_norm:3.3445 \n",
      "step129:loss:5.289895057678223. time per iter: 79.63ms,tok/sec:1607.52,grad_norm:4.3635 \n",
      "step130:loss:6.488595008850098. time per iter: 76.53ms,tok/sec:1672.60,grad_norm:3.3644 \n",
      "step131:loss:6.887275695800781. time per iter: 71.66ms,tok/sec:1786.18,grad_norm:2.7158 \n",
      "step132:loss:6.413156509399414. time per iter: 73.22ms,tok/sec:1748.22,grad_norm:2.8355 \n",
      "step133:loss:6.34200382232666. time per iter: 70.06ms,tok/sec:1827.11,grad_norm:3.2703 \n",
      "step134:loss:5.825439453125. time per iter: 80.76ms,tok/sec:1584.92,grad_norm:3.1798 \n",
      "step135:loss:5.569599151611328. time per iter: 87.96ms,tok/sec:1455.26,grad_norm:3.4621 \n",
      "step136:loss:5.503776550292969. time per iter: 86.22ms,tok/sec:1484.66,grad_norm:3.9461 \n",
      "step137:loss:5.829719543457031. time per iter: 95.03ms,tok/sec:1346.92,grad_norm:3.0625 \n",
      "step138:loss:6.013083457946777. time per iter: 88.98ms,tok/sec:1438.56,grad_norm:3.2418 \n",
      "step139:loss:5.831413269042969. time per iter: 84.48ms,tok/sec:1515.23,grad_norm:3.4566 \n",
      "step140:loss:6.644163131713867. time per iter: 91.75ms,tok/sec:1395.15,grad_norm:2.8162 \n",
      "step141:loss:6.256089210510254. time per iter: 86.04ms,tok/sec:1487.73,grad_norm:2.9981 \n",
      "step142:loss:6.754804611206055. time per iter: 85.68ms,tok/sec:1493.89,grad_norm:3.2686 \n",
      "step143:loss:5.889650344848633. time per iter: 97.25ms,tok/sec:1316.20,grad_norm:3.3291 \n",
      "step144:loss:5.508026599884033. time per iter: 89.79ms,tok/sec:1425.59,grad_norm:3.8400 \n",
      "step145:loss:4.9147443771362305. time per iter: 83.04ms,tok/sec:1541.36,grad_norm:4.0869 \n",
      "step146:loss:5.381677150726318. time per iter: 86.48ms,tok/sec:1480.04,grad_norm:4.6332 \n",
      "step147:loss:5.720566749572754. time per iter: 84.88ms,tok/sec:1507.97,grad_norm:3.3991 \n",
      "step148:loss:6.097864627838135. time per iter: 83.77ms,tok/sec:1527.98,grad_norm:3.3316 \n",
      "step149:loss:6.742196083068848. time per iter: 81.39ms,tok/sec:1572.59,grad_norm:3.2975 \n",
      "step150:loss:6.3183465003967285. time per iter: 64.77ms,tok/sec:1976.32,grad_norm:3.3282 \n",
      "step151:loss:6.111754417419434. time per iter: 81.03ms,tok/sec:1579.72,grad_norm:3.3095 \n",
      "step152:loss:6.078522682189941. time per iter: 75.92ms,tok/sec:1685.95,grad_norm:3.0911 \n",
      "step153:loss:6.26051664352417. time per iter: 82.23ms,tok/sec:1556.66,grad_norm:3.1242 \n",
      "step154:loss:6.546573638916016. time per iter: 76.07ms,tok/sec:1682.70,grad_norm:3.0282 \n",
      "step155:loss:6.745025634765625. time per iter: 83.00ms,tok/sec:1542.21,grad_norm:3.0284 \n",
      "step156:loss:6.003091812133789. time per iter: 77.12ms,tok/sec:1659.75,grad_norm:3.3049 \n",
      "step157:loss:5.5689263343811035. time per iter: 77.12ms,tok/sec:1659.69,grad_norm:3.5769 \n",
      "step158:loss:5.453444957733154. time per iter: 72.86ms,tok/sec:1756.86,grad_norm:3.2053 \n",
      "step159:loss:5.64699649810791. time per iter: 73.09ms,tok/sec:1751.22,grad_norm:3.4600 \n",
      "step160:loss:4.825803756713867. time per iter: 67.63ms,tok/sec:1892.53,grad_norm:4.1781 \n",
      "step161:loss:5.128163814544678. time per iter: 68.60ms,tok/sec:1865.80,grad_norm:3.7478 \n",
      "step162:loss:5.610337257385254. time per iter: 72.77ms,tok/sec:1758.88,grad_norm:4.2383 \n",
      "step163:loss:5.175407409667969. time per iter: 79.72ms,tok/sec:1605.55,grad_norm:4.3329 \n",
      "step164:loss:5.398110389709473. time per iter: 69.23ms,tok/sec:1848.99,grad_norm:4.0216 \n",
      "step165:loss:5.676816940307617. time per iter: 75.05ms,tok/sec:1705.64,grad_norm:4.9316 \n",
      "step166:loss:6.155788898468018. time per iter: 71.18ms,tok/sec:1798.36,grad_norm:4.0641 \n",
      "step167:loss:5.369527339935303. time per iter: 71.05ms,tok/sec:1801.66,grad_norm:2.9430 \n",
      "step168:loss:5.634790420532227. time per iter: 72.66ms,tok/sec:1761.71,grad_norm:3.5741 \n",
      "step169:loss:6.308959484100342. time per iter: 72.99ms,tok/sec:1753.70,grad_norm:3.2985 \n",
      "step170:loss:6.871969223022461. time per iter: 76.08ms,tok/sec:1682.41,grad_norm:3.5380 \n",
      "step171:loss:5.520881652832031. time per iter: 70.01ms,tok/sec:1828.41,grad_norm:3.3776 \n",
      "step172:loss:6.127261638641357. time per iter: 70.14ms,tok/sec:1824.94,grad_norm:4.1446 \n",
      "step173:loss:6.780030727386475. time per iter: 72.89ms,tok/sec:1756.04,grad_norm:3.3029 \n",
      "step174:loss:5.976253032684326. time per iter: 83.17ms,tok/sec:1539.10,grad_norm:3.1459 \n",
      "step175:loss:6.729484558105469. time per iter: 82.14ms,tok/sec:1558.33,grad_norm:3.0661 \n",
      "step176:loss:5.839756011962891. time per iter: 77.64ms,tok/sec:1648.64,grad_norm:3.2778 \n",
      "step177:loss:5.39302396774292. time per iter: 77.22ms,tok/sec:1657.65,grad_norm:4.8168 \n",
      "step178:loss:5.028051853179932. time per iter: 74.33ms,tok/sec:1721.99,grad_norm:4.2819 \n",
      "step179:loss:6.534832954406738. time per iter: 62.59ms,tok/sec:2045.15,grad_norm:4.6924 \n",
      "step180:loss:5.389970779418945. time per iter: 76.23ms,tok/sec:1679.08,grad_norm:3.4807 \n",
      "step181:loss:4.484315872192383. time per iter: 81.50ms,tok/sec:1570.65,grad_norm:3.4697 \n",
      "step182:loss:5.57473611831665. time per iter: 73.04ms,tok/sec:1752.57,grad_norm:3.2865 \n",
      "step183:loss:5.387267112731934. time per iter: 89.69ms,tok/sec:1427.20,grad_norm:3.4775 \n",
      "step184:loss:4.767058372497559. time per iter: 70.79ms,tok/sec:1808.26,grad_norm:3.8265 \n",
      "step185:loss:4.799518585205078. time per iter: 66.10ms,tok/sec:1936.51,grad_norm:3.1205 \n",
      "step186:loss:5.410696029663086. time per iter: 68.66ms,tok/sec:1864.22,grad_norm:5.6943 \n",
      "step187:loss:6.19929838180542. time per iter: 72.63ms,tok/sec:1762.46,grad_norm:3.4847 \n",
      "step188:loss:5.734644889831543. time per iter: 70.13ms,tok/sec:1825.05,grad_norm:3.3873 \n",
      "step189:loss:5.694098472595215. time per iter: 68.40ms,tok/sec:1871.25,grad_norm:3.8407 \n",
      "step190:loss:4.471435546875. time per iter: 75.28ms,tok/sec:1700.40,grad_norm:3.9981 \n",
      "step191:loss:4.496394634246826. time per iter: 74.99ms,tok/sec:1706.81,grad_norm:3.7502 \n",
      "step192:loss:6.263711452484131. time per iter: 71.86ms,tok/sec:1781.26,grad_norm:3.4229 \n",
      "step193:loss:5.734809398651123. time per iter: 75.69ms,tok/sec:1691.05,grad_norm:3.8049 \n",
      "step194:loss:5.1782402992248535. time per iter: 75.99ms,tok/sec:1684.43,grad_norm:4.1408 \n",
      "step195:loss:5.9150543212890625. time per iter: 77.42ms,tok/sec:1653.36,grad_norm:3.2118 \n",
      "step196:loss:5.843225002288818. time per iter: 85.55ms,tok/sec:1496.14,grad_norm:2.9736 \n",
      "step197:loss:4.663708686828613. time per iter: 149.94ms,tok/sec:853.67,grad_norm:3.2523 \n",
      "step198:loss:6.734443664550781. time per iter: 76.04ms,tok/sec:1683.36,grad_norm:3.3592 \n",
      "step199:loss:5.432204723358154. time per iter: 80.70ms,tok/sec:1586.12,grad_norm:3.9519 \n",
      "step200:loss:5.327686309814453. time per iter: 78.11ms,tok/sec:1638.76,grad_norm:3.6850 \n",
      "step201:loss:4.998369216918945. time per iter: 68.76ms,tok/sec:1861.47,grad_norm:3.5308 \n",
      "step202:loss:5.211615562438965. time per iter: 69.49ms,tok/sec:1841.97,grad_norm:4.1959 \n",
      "step203:loss:4.998170852661133. time per iter: 69.26ms,tok/sec:1847.98,grad_norm:4.0686 \n",
      "step204:loss:6.356031894683838. time per iter: 77.94ms,tok/sec:1642.28,grad_norm:3.8018 \n",
      "step205:loss:5.715179443359375. time per iter: 77.11ms,tok/sec:1659.99,grad_norm:3.1006 \n",
      "step206:loss:7.005153656005859. time per iter: 72.45ms,tok/sec:1766.68,grad_norm:3.7337 \n",
      "step207:loss:6.205845355987549. time per iter: 114.55ms,tok/sec:1117.40,grad_norm:3.0121 \n",
      "step208:loss:5.19883918762207. time per iter: 90.86ms,tok/sec:1408.81,grad_norm:5.7519 \n",
      "step209:loss:5.908235549926758. time per iter: 85.64ms,tok/sec:1494.69,grad_norm:3.2957 \n",
      "step210:loss:6.45850944519043. time per iter: 76.58ms,tok/sec:1671.52,grad_norm:3.3105 \n",
      "step211:loss:6.583965301513672. time per iter: 75.12ms,tok/sec:1703.92,grad_norm:3.1226 \n",
      "step212:loss:6.379560470581055. time per iter: 76.40ms,tok/sec:1675.33,grad_norm:3.7033 \n",
      "step213:loss:5.265911102294922. time per iter: 68.75ms,tok/sec:1861.71,grad_norm:4.5727 \n",
      "step214:loss:5.417874336242676. time per iter: 71.91ms,tok/sec:1780.02,grad_norm:4.1036 \n",
      "step215:loss:5.133744716644287. time per iter: 75.80ms,tok/sec:1688.58,grad_norm:4.4247 \n",
      "step216:loss:5.687302589416504. time per iter: 73.04ms,tok/sec:1752.36,grad_norm:3.7274 \n",
      "step217:loss:5.121009349822998. time per iter: 70.12ms,tok/sec:1825.33,grad_norm:4.3293 \n",
      "step218:loss:5.678957939147949. time per iter: 73.80ms,tok/sec:1734.44,grad_norm:3.0461 \n",
      "step219:loss:4.445535182952881. time per iter: 74.67ms,tok/sec:1714.12,grad_norm:4.0761 \n",
      "step220:loss:5.880207061767578. time per iter: 74.67ms,tok/sec:1714.14,grad_norm:3.4347 \n",
      "step221:loss:4.586912631988525. time per iter: 75.91ms,tok/sec:1686.13,grad_norm:5.3070 \n",
      "step222:loss:5.782742023468018. time per iter: 74.87ms,tok/sec:1709.56,grad_norm:4.8020 \n",
      "step223:loss:5.273250102996826. time per iter: 79.82ms,tok/sec:1603.55,grad_norm:3.2054 \n",
      "step224:loss:4.417313098907471. time per iter: 67.40ms,tok/sec:1899.20,grad_norm:3.8238 \n",
      "step225:loss:5.90862512588501. time per iter: 73.39ms,tok/sec:1744.11,grad_norm:3.9802 \n",
      "step226:loss:5.038518905639648. time per iter: 75.56ms,tok/sec:1694.02,grad_norm:4.2328 \n",
      "step227:loss:5.375974655151367. time per iter: 69.06ms,tok/sec:1853.35,grad_norm:3.2849 \n",
      "step228:loss:6.09072208404541. time per iter: 74.63ms,tok/sec:1715.18,grad_norm:3.7609 \n",
      "step229:loss:6.113063812255859. time per iter: 82.13ms,tok/sec:1558.52,grad_norm:4.4665 \n",
      "step230:loss:6.063639163970947. time per iter: 69.24ms,tok/sec:1848.61,grad_norm:4.4150 \n",
      "step231:loss:6.061502456665039. time per iter: 76.78ms,tok/sec:1667.02,grad_norm:3.5804 \n",
      "step232:loss:6.293975830078125. time per iter: 79.90ms,tok/sec:1601.93,grad_norm:5.4445 \n",
      "step233:loss:7.202081680297852. time per iter: 76.61ms,tok/sec:1670.74,grad_norm:3.3179 \n",
      "step234:loss:5.876344680786133. time per iter: 83.20ms,tok/sec:1538.54,grad_norm:3.6833 \n",
      "step235:loss:5.950033187866211. time per iter: 76.39ms,tok/sec:1675.67,grad_norm:3.5982 \n",
      "step236:loss:5.104891300201416. time per iter: 75.38ms,tok/sec:1698.15,grad_norm:3.6265 \n",
      "step237:loss:4.599081993103027. time per iter: 70.17ms,tok/sec:1824.17,grad_norm:5.4461 \n",
      "step238:loss:4.903000831604004. time per iter: 78.47ms,tok/sec:1631.22,grad_norm:3.3164 \n",
      "step239:loss:5.89532470703125. time per iter: 72.80ms,tok/sec:1758.17,grad_norm:3.7178 \n",
      "step240:loss:4.476395606994629. time per iter: 76.19ms,tok/sec:1680.09,grad_norm:3.7273 \n",
      "step241:loss:5.684643268585205. time per iter: 75.36ms,tok/sec:1698.60,grad_norm:3.0189 \n",
      "step242:loss:5.337077617645264. time per iter: 76.10ms,tok/sec:1682.02,grad_norm:3.3060 \n",
      "step243:loss:5.243846893310547. time per iter: 76.66ms,tok/sec:1669.66,grad_norm:3.7786 \n",
      "step244:loss:5.717331886291504. time per iter: 75.44ms,tok/sec:1696.66,grad_norm:4.8384 \n",
      "step245:loss:6.388836860656738. time per iter: 76.06ms,tok/sec:1682.78,grad_norm:3.3508 \n",
      "step246:loss:6.243767738342285. time per iter: 69.19ms,tok/sec:1849.95,grad_norm:4.1672 \n",
      "step247:loss:6.6043925285339355. time per iter: 71.63ms,tok/sec:1786.97,grad_norm:2.9353 \n",
      "step248:loss:5.7696990966796875. time per iter: 74.09ms,tok/sec:1727.68,grad_norm:3.6377 \n",
      "step249:loss:5.644539833068848. time per iter: 73.68ms,tok/sec:1737.36,grad_norm:3.1833 \n",
      "step250:loss:5.634096145629883. time per iter: 81.10ms,tok/sec:1578.32,grad_norm:4.0367 \n",
      "step251:loss:6.624650001525879. time per iter: 93.08ms,tok/sec:1375.13,grad_norm:3.5475 \n",
      "step252:loss:5.3061203956604. time per iter: 106.80ms,tok/sec:1198.49,grad_norm:3.9208 \n",
      "step253:loss:5.384058952331543. time per iter: 81.00ms,tok/sec:1580.28,grad_norm:3.9338 \n",
      "step254:loss:4.865331172943115. time per iter: 87.99ms,tok/sec:1454.76,grad_norm:4.9854 \n",
      "step255:loss:5.3565568923950195. time per iter: 93.35ms,tok/sec:1371.19,grad_norm:4.0228 \n",
      "step256:loss:5.002549171447754. time per iter: 87.02ms,tok/sec:1470.94,grad_norm:4.3957 \n",
      "step257:loss:6.202568531036377. time per iter: 73.85ms,tok/sec:1733.27,grad_norm:4.2794 \n",
      "step258:loss:5.467372894287109. time per iter: 76.74ms,tok/sec:1667.97,grad_norm:6.0031 \n",
      "step259:loss:5.855412006378174. time per iter: 66.45ms,tok/sec:1926.33,grad_norm:4.1908 \n",
      "step260:loss:6.615055084228516. time per iter: 75.87ms,tok/sec:1687.15,grad_norm:3.8434 \n",
      "step261:loss:6.832038879394531. time per iter: 71.29ms,tok/sec:1795.54,grad_norm:3.8611 \n",
      "step262:loss:6.2670159339904785. time per iter: 80.14ms,tok/sec:1597.18,grad_norm:4.0143 \n",
      "step263:loss:6.886011123657227. time per iter: 72.11ms,tok/sec:1775.18,grad_norm:3.5642 \n",
      "step264:loss:6.976646423339844. time per iter: 77.78ms,tok/sec:1645.70,grad_norm:4.2031 \n",
      "step265:loss:6.770744323730469. time per iter: 73.36ms,tok/sec:1744.72,grad_norm:3.5850 \n",
      "step266:loss:5.701992511749268. time per iter: 78.42ms,tok/sec:1632.22,grad_norm:3.8937 \n",
      "step267:loss:6.208197593688965. time per iter: 68.18ms,tok/sec:1877.36,grad_norm:4.4931 \n",
      "step268:loss:6.002996444702148. time per iter: 76.37ms,tok/sec:1676.12,grad_norm:4.1301 \n",
      "step269:loss:5.348579406738281. time per iter: 68.34ms,tok/sec:1873.01,grad_norm:5.4870 \n",
      "step270:loss:5.510723114013672. time per iter: 76.04ms,tok/sec:1683.36,grad_norm:5.7556 \n",
      "step271:loss:6.002017974853516. time per iter: 76.43ms,tok/sec:1674.80,grad_norm:4.5929 \n",
      "step272:loss:6.429845809936523. time per iter: 83.67ms,tok/sec:1529.83,grad_norm:3.7911 \n",
      "step273:loss:6.091926574707031. time per iter: 76.84ms,tok/sec:1665.80,grad_norm:3.6324 \n",
      "step274:loss:5.656070709228516. time per iter: 83.60ms,tok/sec:1531.17,grad_norm:4.1808 \n",
      "step275:loss:6.266399383544922. time per iter: 83.47ms,tok/sec:1533.41,grad_norm:3.5824 \n",
      "step276:loss:6.286439895629883. time per iter: 123.59ms,tok/sec:1035.64,grad_norm:3.8365 \n",
      "step277:loss:6.215948104858398. time per iter: 85.80ms,tok/sec:1491.86,grad_norm:4.5546 \n",
      "step278:loss:4.906359672546387. time per iter: 63.97ms,tok/sec:2001.05,grad_norm:4.4573 \n",
      "step279:loss:4.302606582641602. time per iter: 72.39ms,tok/sec:1768.24,grad_norm:4.8794 \n",
      "step280:loss:5.010743141174316. time per iter: 79.55ms,tok/sec:1608.97,grad_norm:4.5911 \n",
      "step281:loss:5.067214488983154. time per iter: 75.43ms,tok/sec:1697.00,grad_norm:3.7944 \n",
      "step282:loss:5.938996315002441. time per iter: 76.67ms,tok/sec:1669.45,grad_norm:3.9660 \n",
      "step283:loss:5.494987964630127. time per iter: 72.33ms,tok/sec:1769.74,grad_norm:3.6904 \n",
      "step284:loss:5.156899452209473. time per iter: 79.18ms,tok/sec:1616.52,grad_norm:3.8247 \n",
      "step285:loss:5.155843734741211. time per iter: 82.74ms,tok/sec:1546.96,grad_norm:3.9666 \n",
      "step286:loss:5.222917556762695. time per iter: 71.25ms,tok/sec:1796.43,grad_norm:3.7348 \n",
      "step287:loss:5.324674606323242. time per iter: 77.55ms,tok/sec:1650.54,grad_norm:3.8039 \n",
      "step288:loss:5.746539115905762. time per iter: 71.97ms,tok/sec:1778.42,grad_norm:3.4453 \n",
      "step289:loss:5.031555652618408. time per iter: 79.69ms,tok/sec:1606.29,grad_norm:3.8013 \n",
      "step290:loss:5.465658187866211. time per iter: 70.06ms,tok/sec:1826.97,grad_norm:3.1987 \n",
      "step291:loss:5.331445693969727. time per iter: 80.21ms,tok/sec:1595.83,grad_norm:3.4744 \n",
      "step292:loss:6.183047771453857. time per iter: 72.59ms,tok/sec:1763.24,grad_norm:3.5329 \n",
      "step293:loss:5.487759590148926. time per iter: 74.85ms,tok/sec:1709.98,grad_norm:4.4194 \n",
      "step294:loss:4.780052661895752. time per iter: 77.57ms,tok/sec:1650.11,grad_norm:3.7143 \n",
      "step295:loss:4.410550117492676. time per iter: 82.18ms,tok/sec:1557.57,grad_norm:4.7483 \n",
      "step296:loss:5.431061744689941. time per iter: 72.49ms,tok/sec:1765.83,grad_norm:3.4383 \n",
      "step297:loss:5.771128177642822. time per iter: 72.93ms,tok/sec:1755.01,grad_norm:3.6081 \n",
      "step298:loss:6.042817115783691. time per iter: 71.94ms,tok/sec:1779.21,grad_norm:3.3407 \n",
      "step299:loss:6.281467437744141. time per iter: 78.26ms,tok/sec:1635.48,grad_norm:3.3115 \n",
      "step300:loss:6.051425933837891. time per iter: 76.59ms,tok/sec:1671.14,grad_norm:3.3759 \n",
      "step301:loss:6.27023458480835. time per iter: 73.38ms,tok/sec:1744.38,grad_norm:3.5711 \n",
      "step302:loss:5.016350746154785. time per iter: 76.74ms,tok/sec:1667.89,grad_norm:3.2918 \n",
      "step303:loss:5.61722993850708. time per iter: 76.27ms,tok/sec:1678.23,grad_norm:3.6421 \n",
      "step304:loss:5.294568061828613. time per iter: 82.76ms,tok/sec:1546.65,grad_norm:3.8418 \n",
      "step305:loss:5.6515374183654785. time per iter: 79.28ms,tok/sec:1614.50,grad_norm:3.9559 \n",
      "step306:loss:4.353524208068848. time per iter: 81.12ms,tok/sec:1577.85,grad_norm:3.1251 \n",
      "step307:loss:5.962577819824219. time per iter: 76.08ms,tok/sec:1682.47,grad_norm:3.1612 \n",
      "step308:loss:4.505797386169434. time per iter: 80.20ms,tok/sec:1596.10,grad_norm:3.7505 \n",
      "step309:loss:6.191306114196777. time per iter: 76.48ms,tok/sec:1673.61,grad_norm:3.7888 \n",
      "step310:loss:4.383513450622559. time per iter: 77.01ms,tok/sec:1662.17,grad_norm:3.4167 \n",
      "step311:loss:4.812014102935791. time per iter: 78.08ms,tok/sec:1639.34,grad_norm:3.3800 \n",
      "step312:loss:6.302875995635986. time per iter: 75.77ms,tok/sec:1689.25,grad_norm:3.2991 \n",
      "step313:loss:5.484534740447998. time per iter: 74.64ms,tok/sec:1714.83,grad_norm:3.8614 \n",
      "step314:loss:5.7371015548706055. time per iter: 65.09ms,tok/sec:1966.46,grad_norm:3.2565 \n",
      "step315:loss:5.830232620239258. time per iter: 79.89ms,tok/sec:1602.21,grad_norm:3.3101 \n",
      "step316:loss:4.885424613952637. time per iter: 76.14ms,tok/sec:1681.00,grad_norm:3.6156 \n",
      "step317:loss:6.862678527832031. time per iter: 75.40ms,tok/sec:1697.56,grad_norm:3.6535 \n",
      "step318:loss:5.8055033683776855. time per iter: 89.32ms,tok/sec:1433.00,grad_norm:3.7762 \n",
      "step319:loss:6.777458190917969. time per iter: 128.29ms,tok/sec:997.71,grad_norm:3.7903 \n",
      "step320:loss:4.767006874084473. time per iter: 89.27ms,tok/sec:1433.90,grad_norm:4.3424 \n",
      "step321:loss:5.722291946411133. time per iter: 89.39ms,tok/sec:1431.98,grad_norm:4.5461 \n",
      "step322:loss:5.357510566711426. time per iter: 108.41ms,tok/sec:1180.66,grad_norm:4.7201 \n",
      "step323:loss:6.640838623046875. time per iter: 106.40ms,tok/sec:1202.99,grad_norm:3.3216 \n",
      "step324:loss:6.555377960205078. time per iter: 87.44ms,tok/sec:1463.85,grad_norm:3.8198 \n",
      "step325:loss:6.155950546264648. time per iter: 69.82ms,tok/sec:1833.16,grad_norm:5.4725 \n",
      "step326:loss:5.9911088943481445. time per iter: 74.24ms,tok/sec:1724.08,grad_norm:3.4708 \n",
      "step327:loss:6.288496494293213. time per iter: 83.04ms,tok/sec:1541.36,grad_norm:4.0024 \n",
      "step328:loss:6.28337287902832. time per iter: 94.55ms,tok/sec:1353.80,grad_norm:4.0430 \n",
      "step329:loss:5.422457218170166. time per iter: 85.66ms,tok/sec:1494.27,grad_norm:3.9320 \n",
      "step330:loss:5.833436965942383. time per iter: 162.89ms,tok/sec:785.80,grad_norm:3.6076 \n",
      "step331:loss:5.543889999389648. time per iter: 65.45ms,tok/sec:1955.74,grad_norm:3.4800 \n",
      "step332:loss:6.83740234375. time per iter: 76.07ms,tok/sec:1682.75,grad_norm:3.4735 \n",
      "step333:loss:6.755781173706055. time per iter: 71.87ms,tok/sec:1780.93,grad_norm:4.6868 \n",
      "step334:loss:5.995168685913086. time per iter: 69.22ms,tok/sec:1849.16,grad_norm:3.9255 \n",
      "step335:loss:5.590136528015137. time per iter: 92.74ms,tok/sec:1380.26,grad_norm:3.8923 \n",
      "step336:loss:6.355886459350586. time per iter: 76.49ms,tok/sec:1673.37,grad_norm:3.6997 \n",
      "step337:loss:6.468972206115723. time per iter: 78.08ms,tok/sec:1639.36,grad_norm:3.7942 \n",
      "step338:loss:6.3009796142578125. time per iter: 62.81ms,tok/sec:2037.92,grad_norm:3.3671 \n",
      "step339:loss:6.259775161743164. time per iter: 76.97ms,tok/sec:1662.93,grad_norm:3.9643 \n",
      "step340:loss:5.526648044586182. time per iter: 74.21ms,tok/sec:1724.83,grad_norm:3.6391 \n",
      "step341:loss:5.226165294647217. time per iter: 75.55ms,tok/sec:1694.14,grad_norm:4.3722 \n",
      "step342:loss:5.218487739562988. time per iter: 69.22ms,tok/sec:1849.19,grad_norm:4.5888 \n",
      "step343:loss:5.457935333251953. time per iter: 82.69ms,tok/sec:1547.88,grad_norm:3.8592 \n",
      "step344:loss:5.4895195960998535. time per iter: 76.25ms,tok/sec:1678.73,grad_norm:5.1935 \n",
      "step345:loss:6.857109546661377. time per iter: 65.69ms,tok/sec:1948.40,grad_norm:4.2547 \n",
      "step346:loss:5.188681602478027. time per iter: 75.44ms,tok/sec:1696.80,grad_norm:3.6865 \n",
      "step347:loss:5.541540145874023. time per iter: 75.59ms,tok/sec:1693.39,grad_norm:3.8931 \n",
      "step348:loss:6.297479629516602. time per iter: 73.01ms,tok/sec:1753.24,grad_norm:3.8743 \n",
      "step349:loss:5.494815349578857. time per iter: 75.59ms,tok/sec:1693.29,grad_norm:3.2772 \n",
      "step350:loss:5.1585774421691895. time per iter: 91.42ms,tok/sec:1400.11,grad_norm:4.2463 \n",
      "step351:loss:6.141064167022705. time per iter: 79.77ms,tok/sec:1604.59,grad_norm:4.3492 \n",
      "step352:loss:5.571674346923828. time per iter: 76.74ms,tok/sec:1667.99,grad_norm:4.1658 \n",
      "step353:loss:5.918134689331055. time per iter: 75.85ms,tok/sec:1687.50,grad_norm:3.7348 \n",
      "step354:loss:6.364838600158691. time per iter: 80.90ms,tok/sec:1582.25,grad_norm:3.8288 \n",
      "step355:loss:5.557400703430176. time per iter: 76.25ms,tok/sec:1678.73,grad_norm:3.5342 \n",
      "step356:loss:6.3523383140563965. time per iter: 77.33ms,tok/sec:1655.29,grad_norm:3.3586 \n",
      "step357:loss:5.260215759277344. time per iter: 79.84ms,tok/sec:1603.16,grad_norm:3.6939 \n",
      "step358:loss:5.443779945373535. time per iter: 71.34ms,tok/sec:1794.19,grad_norm:4.4282 \n",
      "step359:loss:6.3102593421936035. time per iter: 77.76ms,tok/sec:1646.11,grad_norm:4.3108 \n",
      "step360:loss:5.038888931274414. time per iter: 76.29ms,tok/sec:1677.85,grad_norm:5.7814 \n",
      "step361:loss:5.798650741577148. time per iter: 73.74ms,tok/sec:1735.84,grad_norm:3.7407 \n",
      "step362:loss:5.612180709838867. time per iter: 78.00ms,tok/sec:1641.05,grad_norm:3.9567 \n",
      "step363:loss:5.664226055145264. time per iter: 77.18ms,tok/sec:1658.41,grad_norm:3.9302 \n",
      "step364:loss:6.482526779174805. time per iter: 76.83ms,tok/sec:1666.03,grad_norm:4.9088 \n",
      "step365:loss:5.188995838165283. time per iter: 75.73ms,tok/sec:1690.14,grad_norm:5.8415 \n",
      "step366:loss:5.895358085632324. time per iter: 77.96ms,tok/sec:1641.88,grad_norm:4.8768 \n",
      "step367:loss:5.840342044830322. time per iter: 74.33ms,tok/sec:1722.10,grad_norm:4.7311 \n",
      "step368:loss:6.7398576736450195. time per iter: 75.82ms,tok/sec:1688.27,grad_norm:3.8385 \n",
      "step369:loss:7.576942443847656. time per iter: 76.21ms,tok/sec:1679.50,grad_norm:4.4126 \n",
      "step370:loss:6.5569305419921875. time per iter: 76.76ms,tok/sec:1667.61,grad_norm:3.7041 \n",
      "step371:loss:6.819450378417969. time per iter: 68.98ms,tok/sec:1855.62,grad_norm:3.5272 \n",
      "step372:loss:6.733339309692383. time per iter: 75.29ms,tok/sec:1700.05,grad_norm:3.7797 \n",
      "step373:loss:6.3153791427612305. time per iter: 75.89ms,tok/sec:1686.72,grad_norm:3.4572 \n",
      "step374:loss:6.313243865966797. time per iter: 76.15ms,tok/sec:1680.94,grad_norm:3.7125 \n",
      "step375:loss:6.771963119506836. time per iter: 76.77ms,tok/sec:1667.32,grad_norm:3.6669 \n",
      "step376:loss:6.839593887329102. time per iter: 75.64ms,tok/sec:1692.16,grad_norm:3.6273 \n",
      "step377:loss:6.38122034072876. time per iter: 75.94ms,tok/sec:1685.50,grad_norm:3.8504 \n",
      "step378:loss:6.632923126220703. time per iter: 75.75ms,tok/sec:1689.78,grad_norm:3.9552 \n",
      "step379:loss:6.608909606933594. time per iter: 75.29ms,tok/sec:1700.04,grad_norm:3.6614 \n",
      "step380:loss:6.397472858428955. time per iter: 63.83ms,tok/sec:2005.19,grad_norm:3.8636 \n",
      "step381:loss:5.969918727874756. time per iter: 53.28ms,tok/sec:2402.46,grad_norm:3.8790 \n",
      "step382:loss:6.061814308166504. time per iter: 41.57ms,tok/sec:3079.09,grad_norm:3.9664 \n",
      "step383:loss:6.401795387268066. time per iter: 54.41ms,tok/sec:2352.51,grad_norm:4.3102 \n",
      "step384:loss:6.966915130615234. time per iter: 54.93ms,tok/sec:2330.31,grad_norm:3.9678 \n",
      "step385:loss:6.8117451667785645. time per iter: 55.20ms,tok/sec:2319.02,grad_norm:5.5186 \n",
      "step386:loss:6.617568492889404. time per iter: 56.60ms,tok/sec:2261.51,grad_norm:5.4405 \n",
      "step387:loss:6.597365856170654. time per iter: 58.42ms,tok/sec:2191.13,grad_norm:3.9834 \n",
      "step388:loss:6.428466320037842. time per iter: 58.50ms,tok/sec:2187.90,grad_norm:3.9692 \n",
      "step389:loss:6.408947944641113. time per iter: 56.42ms,tok/sec:2268.52,grad_norm:4.7369 \n",
      "step390:loss:6.999078273773193. time per iter: 60.09ms,tok/sec:2130.07,grad_norm:4.4311 \n",
      "step391:loss:6.815916538238525. time per iter: 54.27ms,tok/sec:2358.61,grad_norm:4.0974 \n",
      "step392:loss:6.4803619384765625. time per iter: 59.18ms,tok/sec:2163.03,grad_norm:4.4956 \n",
      "step393:loss:6.359449863433838. time per iter: 53.54ms,tok/sec:2390.68,grad_norm:4.8409 \n",
      "step394:loss:6.199836254119873. time per iter: 55.89ms,tok/sec:2290.01,grad_norm:4.6335 \n",
      "step395:loss:6.657808780670166. time per iter: 47.93ms,tok/sec:2670.44,grad_norm:4.5579 \n",
      "step396:loss:5.731404781341553. time per iter: 55.38ms,tok/sec:2311.15,grad_norm:4.5969 \n",
      "step397:loss:6.004274845123291. time per iter: 54.84ms,tok/sec:2334.04,grad_norm:4.8593 \n",
      "step398:loss:6.240630149841309. time per iter: 49.98ms,tok/sec:2560.99,grad_norm:3.7563 \n",
      "step399:loss:5.865602493286133. time per iter: 54.54ms,tok/sec:2346.72,grad_norm:4.9065 \n",
      "step400:loss:5.635278224945068. time per iter: 54.80ms,tok/sec:2335.85,grad_norm:5.6138 \n",
      "step401:loss:5.689948558807373. time per iter: 54.64ms,tok/sec:2342.57,grad_norm:9.0535 \n",
      "step402:loss:6.1884765625. time per iter: 55.65ms,tok/sec:2299.98,grad_norm:6.9440 \n",
      "step403:loss:6.902787685394287. time per iter: 55.40ms,tok/sec:2310.61,grad_norm:4.6132 \n",
      "step404:loss:6.499732971191406. time per iter: 54.40ms,tok/sec:2353.14,grad_norm:5.6279 \n",
      "step405:loss:5.981467247009277. time per iter: 57.36ms,tok/sec:2231.35,grad_norm:4.9316 \n",
      "step406:loss:5.256529331207275. time per iter: 55.12ms,tok/sec:2322.01,grad_norm:5.9971 \n",
      "step407:loss:4.696990489959717. time per iter: 54.50ms,tok/sec:2348.58,grad_norm:6.7687 \n",
      "step408:loss:5.732097625732422. time per iter: 54.95ms,tok/sec:2329.43,grad_norm:4.7953 \n",
      "step409:loss:6.434196949005127. time per iter: 48.90ms,tok/sec:2617.54,grad_norm:3.3680 \n",
      "step410:loss:5.709456443786621. time per iter: 55.06ms,tok/sec:2324.54,grad_norm:5.1817 \n",
      "step411:loss:5.835753440856934. time per iter: 54.39ms,tok/sec:2353.48,grad_norm:4.9665 \n",
      "step412:loss:6.775108814239502. time per iter: 55.75ms,tok/sec:2295.88,grad_norm:4.2766 \n",
      "step413:loss:6.45198392868042. time per iter: 55.46ms,tok/sec:2308.04,grad_norm:3.8218 \n",
      "step414:loss:6.287968635559082. time per iter: 55.99ms,tok/sec:2286.13,grad_norm:4.8874 \n",
      "step415:loss:6.600584030151367. time per iter: 55.61ms,tok/sec:2301.61,grad_norm:5.3360 \n",
      "step416:loss:6.228359699249268. time per iter: 54.42ms,tok/sec:2352.15,grad_norm:4.6331 \n",
      "step417:loss:6.456866264343262. time per iter: 55.49ms,tok/sec:2306.52,grad_norm:4.6533 \n",
      "step418:loss:6.930120468139648. time per iter: 48.71ms,tok/sec:2627.82,grad_norm:5.8306 \n",
      "step419:loss:6.193586349487305. time per iter: 54.99ms,tok/sec:2327.82,grad_norm:4.7785 \n",
      "step420:loss:6.3223371505737305. time per iter: 54.76ms,tok/sec:2337.36,grad_norm:5.4758 \n",
      "step421:loss:6.549504280090332. time per iter: 55.55ms,tok/sec:2304.07,grad_norm:3.9495 \n",
      "step422:loss:6.581182956695557. time per iter: 55.32ms,tok/sec:2313.85,grad_norm:4.5971 \n",
      "step423:loss:6.371127605438232. time per iter: 53.81ms,tok/sec:2378.58,grad_norm:4.1770 \n",
      "step424:loss:5.78921365737915. time per iter: 55.64ms,tok/sec:2300.32,grad_norm:4.6884 \n",
      "step425:loss:6.842748641967773. time per iter: 52.50ms,tok/sec:2437.88,grad_norm:4.1216 \n",
      "step426:loss:6.030502796173096. time per iter: 59.12ms,tok/sec:2165.17,grad_norm:4.6105 \n",
      "step427:loss:5.812024116516113. time per iter: 48.81ms,tok/sec:2622.35,grad_norm:4.0783 \n",
      "step428:loss:5.963131427764893. time per iter: 57.96ms,tok/sec:2208.44,grad_norm:3.9317 \n",
      "step429:loss:6.089287757873535. time per iter: 56.17ms,tok/sec:2278.96,grad_norm:4.8658 \n",
      "step430:loss:5.6880598068237305. time per iter: 52.80ms,tok/sec:2424.38,grad_norm:4.4294 \n",
      "step431:loss:6.195934295654297. time per iter: 55.32ms,tok/sec:2313.91,grad_norm:4.6973 \n",
      "step432:loss:5.916377067565918. time per iter: 55.27ms,tok/sec:2316.02,grad_norm:4.6058 \n",
      "step433:loss:6.104931831359863. time per iter: 59.49ms,tok/sec:2151.46,grad_norm:3.6283 \n",
      "step434:loss:6.172360420227051. time per iter: 53.21ms,tok/sec:2405.40,grad_norm:4.4257 \n",
      "step435:loss:6.416641712188721. time per iter: 53.95ms,tok/sec:2372.46,grad_norm:4.8699 \n",
      "step436:loss:6.4400224685668945. time per iter: 51.57ms,tok/sec:2482.23,grad_norm:4.6571 \n",
      "step437:loss:6.131710529327393. time per iter: 53.19ms,tok/sec:2406.27,grad_norm:4.3500 \n",
      "step438:loss:6.99984884262085. time per iter: 54.19ms,tok/sec:2361.97,grad_norm:5.0397 \n",
      "step439:loss:5.518980979919434. time per iter: 56.17ms,tok/sec:2278.89,grad_norm:5.4175 \n",
      "step440:loss:5.935246467590332. time per iter: 54.57ms,tok/sec:2345.78,grad_norm:5.0145 \n",
      "step441:loss:6.506877899169922. time per iter: 48.19ms,tok/sec:2656.26,grad_norm:4.5029 \n",
      "step442:loss:6.014865398406982. time per iter: 55.44ms,tok/sec:2308.78,grad_norm:4.5735 \n",
      "step443:loss:5.660543441772461. time per iter: 58.04ms,tok/sec:2205.47,grad_norm:4.7216 \n",
      "step444:loss:6.540005683898926. time per iter: 52.93ms,tok/sec:2418.21,grad_norm:4.2692 \n",
      "step445:loss:5.9544219970703125. time per iter: 55.09ms,tok/sec:2323.46,grad_norm:4.4270 \n",
      "step446:loss:5.849164962768555. time per iter: 55.03ms,tok/sec:2326.12,grad_norm:3.7866 \n",
      "step447:loss:5.561280727386475. time per iter: 55.93ms,tok/sec:2288.54,grad_norm:3.8837 \n",
      "step448:loss:5.242781639099121. time per iter: 54.57ms,tok/sec:2345.79,grad_norm:4.7002 \n",
      "step449:loss:5.597696304321289. time per iter: 52.36ms,tok/sec:2444.46,grad_norm:4.9083 \n",
      "step450:loss:5.801529884338379. time per iter: 46.09ms,tok/sec:2777.25,grad_norm:5.2381 \n",
      "step451:loss:6.261778831481934. time per iter: 55.56ms,tok/sec:2303.67,grad_norm:4.2938 \n",
      "step452:loss:5.411723613739014. time per iter: 53.59ms,tok/sec:2388.58,grad_norm:3.8022 \n",
      "step453:loss:5.673799514770508. time per iter: 55.84ms,tok/sec:2292.30,grad_norm:4.1164 \n",
      "step454:loss:6.093542098999023. time per iter: 54.82ms,tok/sec:2335.05,grad_norm:4.0565 \n",
      "step455:loss:6.904666900634766. time per iter: 49.25ms,tok/sec:2598.75,grad_norm:4.0487 \n",
      "step456:loss:6.642889976501465. time per iter: 54.55ms,tok/sec:2346.48,grad_norm:4.8210 \n",
      "step457:loss:6.409104347229004. time per iter: 55.11ms,tok/sec:2322.78,grad_norm:5.2847 \n",
      "step458:loss:6.950139999389648. time per iter: 55.81ms,tok/sec:2293.43,grad_norm:4.5567 \n",
      "step459:loss:6.847940444946289. time per iter: 52.13ms,tok/sec:2455.16,grad_norm:4.0487 \n",
      "step460:loss:6.018791198730469. time per iter: 59.98ms,tok/sec:2134.10,grad_norm:4.0321 \n",
      "step461:loss:6.470593452453613. time per iter: 54.26ms,tok/sec:2358.91,grad_norm:3.6052 \n",
      "step462:loss:5.726597785949707. time per iter: 55.88ms,tok/sec:2290.55,grad_norm:6.9227 \n",
      "step463:loss:5.732245445251465. time per iter: 55.61ms,tok/sec:2301.87,grad_norm:5.3214 \n",
      "step464:loss:6.0086669921875. time per iter: 49.15ms,tok/sec:2604.45,grad_norm:6.2796 \n",
      "step465:loss:5.6803879737854. time per iter: 54.63ms,tok/sec:2343.23,grad_norm:6.4524 \n",
      "step466:loss:5.711984634399414. time per iter: 57.25ms,tok/sec:2235.89,grad_norm:8.3425 \n",
      "step467:loss:6.949941635131836. time per iter: 58.43ms,tok/sec:2190.61,grad_norm:6.1449 \n",
      "step468:loss:5.946534156799316. time per iter: 51.82ms,tok/sec:2470.21,grad_norm:5.0880 \n",
      "step469:loss:5.667415618896484. time per iter: 55.69ms,tok/sec:2298.30,grad_norm:6.1622 \n",
      "step470:loss:4.893857955932617. time per iter: 54.12ms,tok/sec:2365.32,grad_norm:5.5842 \n",
      "step471:loss:5.192326545715332. time per iter: 56.61ms,tok/sec:2261.09,grad_norm:6.3449 \n",
      "step472:loss:6.3356852531433105. time per iter: 55.71ms,tok/sec:2297.78,grad_norm:6.8160 \n",
      "step473:loss:5.851934432983398. time per iter: 47.25ms,tok/sec:2709.06,grad_norm:4.4649 \n",
      "step474:loss:5.553278923034668. time per iter: 54.94ms,tok/sec:2329.97,grad_norm:4.4549 \n",
      "step475:loss:6.023254871368408. time per iter: 54.39ms,tok/sec:2353.51,grad_norm:4.2047 \n",
      "step476:loss:5.256155967712402. time per iter: 55.73ms,tok/sec:2296.75,grad_norm:4.9680 \n",
      "step477:loss:5.3783650398254395. time per iter: 55.69ms,tok/sec:2298.55,grad_norm:3.7956 \n",
      "step478:loss:5.395978927612305. time per iter: 54.17ms,tok/sec:2362.90,grad_norm:3.9590 \n",
      "step479:loss:5.154098987579346. time per iter: 56.11ms,tok/sec:2281.22,grad_norm:3.8886 \n",
      "step480:loss:5.258001327514648. time per iter: 54.24ms,tok/sec:2359.83,grad_norm:4.9617 \n",
      "step481:loss:5.187946796417236. time per iter: 57.49ms,tok/sec:2226.36,grad_norm:4.8960 \n",
      "step482:loss:5.286467552185059. time per iter: 47.62ms,tok/sec:2687.92,grad_norm:4.2568 \n",
      "step483:loss:6.142185688018799. time per iter: 59.31ms,tok/sec:2158.01,grad_norm:3.6747 \n",
      "step484:loss:5.974545955657959. time per iter: 56.29ms,tok/sec:2273.86,grad_norm:4.6138 \n",
      "step485:loss:6.110295295715332. time per iter: 54.50ms,tok/sec:2348.56,grad_norm:4.5855 \n",
      "step486:loss:6.277659893035889. time per iter: 56.76ms,tok/sec:2255.30,grad_norm:4.8197 \n",
      "step487:loss:6.105385780334473. time per iter: 69.20ms,tok/sec:1849.81,grad_norm:4.3135 \n",
      "step488:loss:5.948009490966797. time per iter: 56.31ms,tok/sec:2272.95,grad_norm:6.1756 \n",
      "step489:loss:5.9254021644592285. time per iter: 54.50ms,tok/sec:2348.50,grad_norm:6.1516 \n",
      "step490:loss:6.401059627532959. time per iter: 54.04ms,tok/sec:2368.69,grad_norm:5.1634 \n",
      "step491:loss:5.498829364776611. time per iter: 46.90ms,tok/sec:2729.18,grad_norm:4.4610 \n",
      "step492:loss:6.2034711837768555. time per iter: 56.43ms,tok/sec:2268.38,grad_norm:3.4278 \n",
      "step493:loss:5.8339056968688965. time per iter: 55.71ms,tok/sec:2297.61,grad_norm:4.9069 \n",
      "step494:loss:6.185246467590332. time per iter: 60.41ms,tok/sec:2118.74,grad_norm:4.7542 \n",
      "step495:loss:6.350893497467041. time per iter: 51.58ms,tok/sec:2481.50,grad_norm:3.8645 \n",
      "step496:loss:5.688279628753662. time per iter: 54.03ms,tok/sec:2368.97,grad_norm:4.2386 \n",
      "step497:loss:5.624309539794922. time per iter: 55.68ms,tok/sec:2298.87,grad_norm:4.9610 \n",
      "step498:loss:6.013008117675781. time per iter: 57.10ms,tok/sec:2241.86,grad_norm:4.1091 \n",
      "step499:loss:6.203836917877197. time per iter: 53.78ms,tok/sec:2379.91,grad_norm:3.7617 \n",
      "step500:loss:6.2960405349731445. time per iter: 51.12ms,tok/sec:2503.93,grad_norm:4.0139 \n",
      "step501:loss:5.982244968414307. time per iter: 56.79ms,tok/sec:2253.87,grad_norm:5.8868 \n",
      "step502:loss:6.059666633605957. time per iter: 51.70ms,tok/sec:2475.75,grad_norm:3.7737 \n",
      "step503:loss:6.097673416137695. time per iter: 53.16ms,tok/sec:2407.71,grad_norm:4.1470 \n",
      "step504:loss:6.516482353210449. time per iter: 54.54ms,tok/sec:2347.09,grad_norm:4.6155 \n",
      "step505:loss:5.870129585266113. time per iter: 50.11ms,tok/sec:2554.53,grad_norm:7.3978 \n",
      "step506:loss:6.104221343994141. time per iter: 55.29ms,tok/sec:2315.21,grad_norm:5.1524 \n",
      "step507:loss:6.39177131652832. time per iter: 54.78ms,tok/sec:2336.70,grad_norm:3.9050 \n",
      "step508:loss:6.048332214355469. time per iter: 54.76ms,tok/sec:2337.58,grad_norm:4.1806 \n",
      "step509:loss:6.179447174072266. time per iter: 46.44ms,tok/sec:2756.49,grad_norm:4.5248 \n",
      "step510:loss:6.10030460357666. time per iter: 51.88ms,tok/sec:2467.02,grad_norm:4.1062 \n",
      "step511:loss:5.419551849365234. time per iter: 54.75ms,tok/sec:2337.70,grad_norm:4.3803 \n",
      "step512:loss:5.2837419509887695. time per iter: 56.08ms,tok/sec:2282.61,grad_norm:4.2966 \n",
      "step513:loss:5.663153648376465. time per iter: 61.13ms,tok/sec:2093.98,grad_norm:4.3785 \n",
      "step514:loss:5.144690036773682. time per iter: 49.12ms,tok/sec:2606.08,grad_norm:5.1334 \n",
      "step515:loss:5.619438171386719. time per iter: 54.75ms,tok/sec:2337.96,grad_norm:3.7466 \n",
      "step516:loss:5.678154945373535. time per iter: 57.22ms,tok/sec:2237.01,grad_norm:3.8557 \n",
      "step517:loss:5.87458610534668. time per iter: 53.17ms,tok/sec:2407.48,grad_norm:4.0117 \n",
      "step518:loss:5.882180213928223. time per iter: 56.12ms,tok/sec:2280.78,grad_norm:3.9107 \n",
      "step519:loss:5.8609137535095215. time per iter: 56.62ms,tok/sec:2260.77,grad_norm:4.8447 \n",
      "step520:loss:6.288491249084473. time per iter: 57.78ms,tok/sec:2215.30,grad_norm:4.0306 \n",
      "step521:loss:5.95078182220459. time per iter: 57.77ms,tok/sec:2215.85,grad_norm:4.3615 \n",
      "step522:loss:6.165472030639648. time per iter: 55.66ms,tok/sec:2299.76,grad_norm:4.2132 \n",
      "step523:loss:5.945155143737793. time per iter: 42.95ms,tok/sec:2979.97,grad_norm:5.3132 \n",
      "step524:loss:5.878730773925781. time per iter: 55.15ms,tok/sec:2320.79,grad_norm:4.8432 \n",
      "step525:loss:5.974370002746582. time per iter: 51.95ms,tok/sec:2463.99,grad_norm:6.3045 \n",
      "step526:loss:6.221780300140381. time per iter: 51.86ms,tok/sec:2468.12,grad_norm:4.4617 \n",
      "step527:loss:5.525516510009766. time per iter: 52.91ms,tok/sec:2419.19,grad_norm:4.4847 \n",
      "step528:loss:5.517875671386719. time per iter: 54.76ms,tok/sec:2337.45,grad_norm:4.5001 \n",
      "step529:loss:6.169949054718018. time per iter: 50.67ms,tok/sec:2526.38,grad_norm:4.1045 \n",
      "step530:loss:5.4801740646362305. time per iter: 57.45ms,tok/sec:2228.08,grad_norm:3.9866 \n",
      "step531:loss:6.073241233825684. time per iter: 52.31ms,tok/sec:2446.84,grad_norm:4.6761 \n",
      "step532:loss:6.392602920532227. time per iter: 50.27ms,tok/sec:2546.08,grad_norm:5.3542 \n",
      "step533:loss:6.144551753997803. time per iter: 54.23ms,tok/sec:2360.24,grad_norm:4.0870 \n",
      "step534:loss:5.575409412384033. time per iter: 53.93ms,tok/sec:2373.56,grad_norm:4.5464 \n",
      "step535:loss:5.859472274780273. time per iter: 52.52ms,tok/sec:2437.35,grad_norm:5.0323 \n",
      "step536:loss:5.687554359436035. time per iter: 58.50ms,tok/sec:2188.17,grad_norm:5.3674 \n",
      "step537:loss:5.484701156616211. time per iter: 43.23ms,tok/sec:2961.25,grad_norm:4.8338 \n",
      "step538:loss:5.2909417152404785. time per iter: 54.47ms,tok/sec:2350.09,grad_norm:4.8112 \n",
      "step539:loss:4.574295520782471. time per iter: 55.45ms,tok/sec:2308.53,grad_norm:6.2697 \n",
      "step540:loss:4.611309051513672. time per iter: 50.10ms,tok/sec:2554.64,grad_norm:5.4403 \n",
      "step541:loss:4.396218776702881. time per iter: 53.95ms,tok/sec:2372.75,grad_norm:4.1135 \n",
      "step542:loss:5.651686668395996. time per iter: 45.47ms,tok/sec:2815.09,grad_norm:6.3523 \n",
      "step543:loss:4.861635208129883. time per iter: 54.30ms,tok/sec:2357.34,grad_norm:5.4054 \n",
      "step544:loss:4.883294105529785. time per iter: 53.74ms,tok/sec:2381.69,grad_norm:5.2894 \n",
      "step545:loss:6.067089080810547. time per iter: 53.50ms,tok/sec:2392.42,grad_norm:4.5410 \n",
      "step546:loss:5.440404415130615. time per iter: 56.22ms,tok/sec:2276.93,grad_norm:5.5308 \n",
      "step547:loss:5.981476783752441. time per iter: 55.69ms,tok/sec:2298.59,grad_norm:4.5950 \n",
      "step548:loss:5.567287445068359. time per iter: 51.38ms,tok/sec:2491.06,grad_norm:4.4771 \n",
      "step549:loss:5.052400588989258. time per iter: 53.98ms,tok/sec:2371.37,grad_norm:3.8729 \n",
      "step550:loss:4.961754322052002. time per iter: 54.82ms,tok/sec:2334.94,grad_norm:5.4332 \n",
      "step551:loss:5.884446144104004. time per iter: 49.03ms,tok/sec:2610.49,grad_norm:4.5408 \n",
      "step552:loss:5.991060733795166. time per iter: 54.07ms,tok/sec:2367.28,grad_norm:4.3745 \n",
      "step553:loss:5.964734077453613. time per iter: 52.23ms,tok/sec:2450.70,grad_norm:4.4965 \n",
      "step554:loss:5.6860246658325195. time per iter: 53.40ms,tok/sec:2397.14,grad_norm:3.8368 \n",
      "step555:loss:5.549807548522949. time per iter: 51.40ms,tok/sec:2490.06,grad_norm:3.9573 \n",
      "step556:loss:5.280241012573242. time per iter: 42.68ms,tok/sec:2999.11,grad_norm:4.4291 \n",
      "step557:loss:5.555009841918945. time per iter: 52.01ms,tok/sec:2460.92,grad_norm:5.3081 \n",
      "step558:loss:5.557641983032227. time per iter: 49.49ms,tok/sec:2586.27,grad_norm:4.8757 \n",
      "step559:loss:5.9387311935424805. time per iter: 54.57ms,tok/sec:2345.68,grad_norm:4.1531 \n",
      "step560:loss:5.352150917053223. time per iter: 50.33ms,tok/sec:2543.09,grad_norm:4.4474 \n",
      "step561:loss:5.661783218383789. time per iter: 45.14ms,tok/sec:2835.32,grad_norm:5.0690 \n",
      "step562:loss:5.3088483810424805. time per iter: 51.87ms,tok/sec:2467.79,grad_norm:6.4201 \n",
      "step563:loss:5.118498802185059. time per iter: 52.44ms,tok/sec:2440.85,grad_norm:5.5646 \n",
      "step564:loss:6.173729419708252. time per iter: 50.18ms,tok/sec:2550.90,grad_norm:4.9521 \n",
      "step565:loss:5.747166633605957. time per iter: 47.68ms,tok/sec:2684.46,grad_norm:3.9259 \n",
      "step566:loss:5.313555717468262. time per iter: 43.58ms,tok/sec:2936.83,grad_norm:4.0237 \n",
      "step567:loss:5.162469863891602. time per iter: 55.25ms,tok/sec:2316.83,grad_norm:5.3517 \n",
      "step568:loss:5.076301574707031. time per iter: 51.56ms,tok/sec:2482.32,grad_norm:4.2505 \n",
      "step569:loss:5.119293212890625. time per iter: 52.80ms,tok/sec:2424.35,grad_norm:4.3282 \n",
      "step570:loss:4.725188732147217. time per iter: 55.52ms,tok/sec:2305.68,grad_norm:5.0092 \n",
      "step571:loss:5.5712995529174805. time per iter: 48.92ms,tok/sec:2616.36,grad_norm:3.5955 \n",
      "step572:loss:5.845893859863281. time per iter: 52.52ms,tok/sec:2437.28,grad_norm:5.0967 \n",
      "step573:loss:4.987155914306641. time per iter: 52.90ms,tok/sec:2419.71,grad_norm:4.1363 \n",
      "step574:loss:5.276198863983154. time per iter: 54.97ms,tok/sec:2328.73,grad_norm:4.0342 \n",
      "step575:loss:6.2866363525390625. time per iter: 54.71ms,tok/sec:2339.69,grad_norm:4.8139 \n",
      "step576:loss:6.138096332550049. time per iter: 51.11ms,tok/sec:2504.17,grad_norm:4.9437 \n",
      "step577:loss:5.857171535491943. time per iter: 53.19ms,tok/sec:2406.63,grad_norm:4.1066 \n",
      "step578:loss:5.499473571777344. time per iter: 61.99ms,tok/sec:2064.83,grad_norm:4.5429 \n",
      "step579:loss:5.614319801330566. time per iter: 55.03ms,tok/sec:2326.13,grad_norm:4.8971 \n",
      "step580:loss:4.7094621658325195. time per iter: 48.06ms,tok/sec:2663.13,grad_norm:5.7164 \n",
      "step581:loss:5.8051605224609375. time per iter: 55.82ms,tok/sec:2293.17,grad_norm:3.9951 \n",
      "step582:loss:5.477688789367676. time per iter: 55.33ms,tok/sec:2313.32,grad_norm:5.1203 \n",
      "step583:loss:5.522963047027588. time per iter: 61.97ms,tok/sec:2065.36,grad_norm:3.6921 \n",
      "step584:loss:5.934584140777588. time per iter: 54.92ms,tok/sec:2330.51,grad_norm:4.2694 \n",
      "step585:loss:5.0582756996154785. time per iter: 55.51ms,tok/sec:2305.75,grad_norm:4.5768 \n",
      "step586:loss:6.360518932342529. time per iter: 54.65ms,tok/sec:2342.28,grad_norm:4.1576 \n",
      "step587:loss:5.662652969360352. time per iter: 56.51ms,tok/sec:2265.03,grad_norm:5.1363 \n",
      "step588:loss:6.028337001800537. time per iter: 55.44ms,tok/sec:2308.93,grad_norm:6.3287 \n",
      "step589:loss:6.370621204376221. time per iter: 47.42ms,tok/sec:2699.46,grad_norm:4.5716 \n",
      "step590:loss:5.386841773986816. time per iter: 54.72ms,tok/sec:2339.05,grad_norm:3.9542 \n",
      "step591:loss:5.699302673339844. time per iter: 55.10ms,tok/sec:2323.16,grad_norm:4.6623 \n",
      "step592:loss:5.88407039642334. time per iter: 52.63ms,tok/sec:2432.00,grad_norm:5.0831 \n",
      "step593:loss:6.253912925720215. time per iter: 55.19ms,tok/sec:2319.37,grad_norm:4.0728 \n",
      "step594:loss:5.703798294067383. time per iter: 50.66ms,tok/sec:2526.55,grad_norm:4.0992 \n",
      "step595:loss:5.334361553192139. time per iter: 50.51ms,tok/sec:2534.02,grad_norm:4.2450 \n",
      "step596:loss:5.460759162902832. time per iter: 54.34ms,tok/sec:2355.40,grad_norm:3.8368 \n",
      "step597:loss:5.049083709716797. time per iter: 49.75ms,tok/sec:2573.08,grad_norm:4.9435 \n",
      "step598:loss:6.134517192840576. time per iter: 51.46ms,tok/sec:2487.32,grad_norm:4.5506 \n",
      "step599:loss:5.133166313171387. time per iter: 52.25ms,tok/sec:2449.72,grad_norm:5.0283 \n",
      "step600:loss:6.152588367462158. time per iter: 60.08ms,tok/sec:2130.65,grad_norm:4.2874 \n",
      "step601:loss:4.843314170837402. time per iter: 54.31ms,tok/sec:2356.87,grad_norm:5.3041 \n",
      "step602:loss:5.433896064758301. time per iter: 52.47ms,tok/sec:2439.57,grad_norm:3.9883 \n",
      "step603:loss:6.581364631652832. time per iter: 45.74ms,tok/sec:2798.45,grad_norm:4.1261 \n",
      "step604:loss:5.988407135009766. time per iter: 45.94ms,tok/sec:2786.13,grad_norm:4.4146 \n",
      "step605:loss:6.000343322753906. time per iter: 53.24ms,tok/sec:2404.39,grad_norm:4.7840 \n",
      "step606:loss:5.840702056884766. time per iter: 53.86ms,tok/sec:2376.45,grad_norm:4.1143 \n",
      "step607:loss:5.383657932281494. time per iter: 52.69ms,tok/sec:2429.42,grad_norm:3.6932 \n",
      "step608:loss:6.759746074676514. time per iter: 45.90ms,tok/sec:2788.84,grad_norm:3.7653 \n",
      "step609:loss:5.699101448059082. time per iter: 52.60ms,tok/sec:2433.35,grad_norm:4.0442 \n",
      "step610:loss:5.046229839324951. time per iter: 54.48ms,tok/sec:2349.48,grad_norm:3.6503 \n",
      "step611:loss:5.152334690093994. time per iter: 54.57ms,tok/sec:2345.58,grad_norm:4.2587 \n",
      "step612:loss:5.569663047790527. time per iter: 54.72ms,tok/sec:2339.39,grad_norm:3.9630 \n",
      "step613:loss:5.538754463195801. time per iter: 44.22ms,tok/sec:2894.67,grad_norm:4.4069 \n",
      "step614:loss:4.415372848510742. time per iter: 54.43ms,tok/sec:2351.59,grad_norm:4.3594 \n",
      "step615:loss:5.6868672370910645. time per iter: 55.57ms,tok/sec:2303.60,grad_norm:5.9051 \n",
      "step616:loss:5.377199649810791. time per iter: 56.13ms,tok/sec:2280.47,grad_norm:5.4937 \n",
      "step617:loss:5.568615436553955. time per iter: 61.93ms,tok/sec:2067.01,grad_norm:5.0558 \n",
      "step618:loss:5.459649085998535. time per iter: 58.18ms,tok/sec:2200.16,grad_norm:3.9104 \n",
      "step619:loss:5.999700546264648. time per iter: 60.38ms,tok/sec:2119.91,grad_norm:4.1844 \n",
      "step620:loss:5.877070426940918. time per iter: 61.68ms,tok/sec:2075.38,grad_norm:4.6798 \n",
      "step621:loss:6.198307037353516. time per iter: 54.80ms,tok/sec:2335.90,grad_norm:3.9861 \n",
      "step622:loss:5.6584882736206055. time per iter: 55.19ms,tok/sec:2319.30,grad_norm:4.2006 \n",
      "step623:loss:5.899106979370117. time per iter: 51.91ms,tok/sec:2465.69,grad_norm:4.5541 \n",
      "step624:loss:5.44573974609375. time per iter: 51.02ms,tok/sec:2508.73,grad_norm:4.0005 \n",
      "step625:loss:6.446778297424316. time per iter: 48.12ms,tok/sec:2659.95,grad_norm:4.8609 \n",
      "step626:loss:5.872043609619141. time per iter: 54.80ms,tok/sec:2335.66,grad_norm:5.2822 \n",
      "step627:loss:5.26003360748291. time per iter: 48.29ms,tok/sec:2650.78,grad_norm:6.5037 \n",
      "step628:loss:5.683558464050293. time per iter: 52.33ms,tok/sec:2445.86,grad_norm:4.8864 \n",
      "step629:loss:6.41344690322876. time per iter: 51.53ms,tok/sec:2483.92,grad_norm:5.3920 \n",
      "step630:loss:6.1224141120910645. time per iter: 51.56ms,tok/sec:2482.72,grad_norm:4.3401 \n",
      "step631:loss:5.890155792236328. time per iter: 51.46ms,tok/sec:2487.60,grad_norm:4.3849 \n",
      "step632:loss:6.22663688659668. time per iter: 61.87ms,tok/sec:2068.84,grad_norm:5.1548 \n",
      "step633:loss:6.158562660217285. time per iter: 48.15ms,tok/sec:2658.22,grad_norm:5.5677 \n",
      "step634:loss:5.8421454429626465. time per iter: 50.11ms,tok/sec:2554.35,grad_norm:4.4034 \n",
      "step635:loss:5.206490516662598. time per iter: 50.87ms,tok/sec:2516.35,grad_norm:5.1690 \n",
      "step636:loss:5.462031364440918. time per iter: 42.35ms,tok/sec:3022.51,grad_norm:5.0473 \n",
      "step637:loss:5.516292095184326. time per iter: 54.50ms,tok/sec:2348.61,grad_norm:5.2796 \n",
      "step638:loss:5.144593238830566. time per iter: 49.75ms,tok/sec:2572.84,grad_norm:4.8176 \n",
      "step639:loss:5.071447849273682. time per iter: 50.10ms,tok/sec:2554.97,grad_norm:5.2379 \n",
      "step640:loss:6.620395660400391. time per iter: 50.08ms,tok/sec:2556.02,grad_norm:5.0497 \n",
      "step641:loss:7.304434299468994. time per iter: 45.31ms,tok/sec:2825.12,grad_norm:4.9793 \n",
      "step642:loss:5.654947280883789. time per iter: 55.20ms,tok/sec:2318.70,grad_norm:4.4185 \n",
      "step643:loss:5.581609725952148. time per iter: 49.47ms,tok/sec:2587.29,grad_norm:5.4316 \n",
      "step644:loss:5.66367244720459. time per iter: 52.19ms,tok/sec:2452.72,grad_norm:4.4678 \n",
      "step645:loss:6.52378511428833. time per iter: 55.22ms,tok/sec:2318.08,grad_norm:3.8772 \n",
      "step646:loss:5.91757869720459. time per iter: 51.53ms,tok/sec:2484.19,grad_norm:4.7878 \n",
      "step647:loss:6.278994560241699. time per iter: 54.79ms,tok/sec:2336.23,grad_norm:4.6231 \n",
      "step648:loss:5.751850605010986. time per iter: 49.11ms,tok/sec:2606.36,grad_norm:5.0247 \n",
      "step649:loss:5.933623790740967. time per iter: 54.03ms,tok/sec:2369.08,grad_norm:4.5164 \n",
      "step650:loss:5.978967189788818. time per iter: 54.92ms,tok/sec:2330.87,grad_norm:5.1925 \n",
      "step651:loss:6.107866287231445. time per iter: 51.16ms,tok/sec:2501.81,grad_norm:4.1815 \n",
      "step652:loss:5.587900638580322. time per iter: 52.00ms,tok/sec:2461.31,grad_norm:3.9206 \n",
      "step653:loss:6.251813888549805. time per iter: 51.80ms,tok/sec:2470.99,grad_norm:4.6028 \n",
      "step654:loss:5.936750888824463. time per iter: 50.27ms,tok/sec:2546.08,grad_norm:5.6529 \n",
      "step655:loss:6.027627944946289. time per iter: 51.37ms,tok/sec:2491.58,grad_norm:4.2061 \n",
      "step656:loss:6.046849727630615. time per iter: 55.95ms,tok/sec:2287.91,grad_norm:4.6863 \n",
      "step657:loss:6.222421169281006. time per iter: 48.64ms,tok/sec:2631.85,grad_norm:3.9720 \n",
      "step658:loss:5.784059524536133. time per iter: 51.64ms,tok/sec:2478.83,grad_norm:3.9796 \n",
      "step659:loss:5.77030086517334. time per iter: 52.60ms,tok/sec:2433.45,grad_norm:6.9032 \n",
      "step660:loss:5.981679439544678. time per iter: 47.00ms,tok/sec:2723.13,grad_norm:6.5488 \n",
      "step661:loss:5.29759407043457. time per iter: 50.53ms,tok/sec:2532.95,grad_norm:5.2402 \n",
      "step662:loss:5.778432846069336. time per iter: 49.83ms,tok/sec:2568.90,grad_norm:6.0062 \n",
      "step663:loss:4.785395622253418. time per iter: 52.12ms,tok/sec:2455.64,grad_norm:6.5931 \n",
      "step664:loss:5.699626922607422. time per iter: 50.87ms,tok/sec:2516.33,grad_norm:4.5038 \n",
      "step665:loss:5.779385566711426. time per iter: 50.96ms,tok/sec:2511.82,grad_norm:5.0149 \n",
      "step666:loss:5.2370710372924805. time per iter: 53.87ms,tok/sec:2376.04,grad_norm:4.9185 \n",
      "step667:loss:5.656539440155029. time per iter: 54.38ms,tok/sec:2353.77,grad_norm:4.5621 \n",
      "step668:loss:4.969725608825684. time per iter: 52.25ms,tok/sec:2449.80,grad_norm:4.7503 \n",
      "step669:loss:5.282773017883301. time per iter: 51.33ms,tok/sec:2493.61,grad_norm:5.8969 \n",
      "step670:loss:5.200872898101807. time per iter: 43.18ms,tok/sec:2964.30,grad_norm:5.7869 \n",
      "step671:loss:6.212350368499756. time per iter: 51.98ms,tok/sec:2462.62,grad_norm:4.9560 \n",
      "step672:loss:5.203955173492432. time per iter: 51.49ms,tok/sec:2486.08,grad_norm:4.1508 \n",
      "step673:loss:4.739027976989746. time per iter: 53.71ms,tok/sec:2383.12,grad_norm:4.7409 \n",
      "step674:loss:5.014950752258301. time per iter: 49.78ms,tok/sec:2571.20,grad_norm:5.1909 \n",
      "step675:loss:4.482839107513428. time per iter: 48.65ms,tok/sec:2631.17,grad_norm:5.2147 \n",
      "step676:loss:3.997824192047119. time per iter: 50.91ms,tok/sec:2514.45,grad_norm:9.5453 \n",
      "step677:loss:5.971067428588867. time per iter: 51.15ms,tok/sec:2502.67,grad_norm:5.1159 \n",
      "step678:loss:5.021389007568359. time per iter: 53.05ms,tok/sec:2412.69,grad_norm:5.0868 \n",
      "step679:loss:5.282078266143799. time per iter: 51.63ms,tok/sec:2479.05,grad_norm:4.4877 \n",
      "step680:loss:5.674598693847656. time per iter: 43.79ms,tok/sec:2923.23,grad_norm:4.4981 \n",
      "step681:loss:6.4822845458984375. time per iter: 53.21ms,tok/sec:2405.69,grad_norm:4.8321 \n",
      "step682:loss:6.798452377319336. time per iter: 50.33ms,tok/sec:2543.46,grad_norm:4.7677 \n",
      "step683:loss:5.131425380706787. time per iter: 60.95ms,tok/sec:2100.13,grad_norm:4.9618 \n",
      "step684:loss:3.9035661220550537. time per iter: 55.24ms,tok/sec:2317.16,grad_norm:6.3070 \n",
      "step685:loss:3.999321460723877. time per iter: 51.94ms,tok/sec:2464.54,grad_norm:6.3658 \n",
      "step686:loss:4.473341464996338. time per iter: 50.40ms,tok/sec:2539.85,grad_norm:5.1404 \n",
      "step687:loss:4.346071243286133. time per iter: 48.55ms,tok/sec:2636.40,grad_norm:6.4483 \n",
      "step688:loss:5.058734893798828. time per iter: 49.45ms,tok/sec:2588.61,grad_norm:4.3646 \n",
      "step689:loss:4.192869663238525. time per iter: 53.96ms,tok/sec:2371.95,grad_norm:7.3051 \n",
      "step690:loss:5.265462398529053. time per iter: 56.49ms,tok/sec:2265.94,grad_norm:4.4831 \n",
      "step691:loss:6.008815765380859. time per iter: 53.60ms,tok/sec:2388.08,grad_norm:5.3191 \n",
      "step692:loss:6.28184700012207. time per iter: 56.33ms,tok/sec:2272.24,grad_norm:5.6465 \n",
      "step693:loss:4.648857116699219. time per iter: 69.14ms,tok/sec:1851.24,grad_norm:5.4085 \n",
      "step694:loss:4.17569637298584. time per iter: 69.87ms,tok/sec:1832.06,grad_norm:9.8192 \n",
      "step695:loss:5.472811698913574. time per iter: 63.63ms,tok/sec:2011.65,grad_norm:4.7987 \n",
      "step696:loss:5.446310997009277. time per iter: 68.93ms,tok/sec:1857.09,grad_norm:4.7741 \n",
      "step697:loss:5.02978515625. time per iter: 52.87ms,tok/sec:2420.98,grad_norm:5.9467 \n",
      "step698:loss:5.097787380218506. time per iter: 62.88ms,tok/sec:2035.61,grad_norm:4.7506 \n",
      "step699:loss:4.9956207275390625. time per iter: 67.20ms,tok/sec:1904.68,grad_norm:5.2345 \n",
      "step700:loss:5.311755180358887. time per iter: 58.01ms,tok/sec:2206.49,grad_norm:6.0405 \n",
      "step701:loss:5.044795513153076. time per iter: 55.33ms,tok/sec:2313.60,grad_norm:5.5195 \n",
      "step702:loss:4.7972822189331055. time per iter: 64.81ms,tok/sec:1974.93,grad_norm:4.7640 \n",
      "step703:loss:6.07535457611084. time per iter: 62.33ms,tok/sec:2053.44,grad_norm:4.5425 \n",
      "step704:loss:5.654819011688232. time per iter: 61.15ms,tok/sec:2093.06,grad_norm:5.3944 \n",
      "step705:loss:5.891861915588379. time per iter: 59.47ms,tok/sec:2152.34,grad_norm:4.8628 \n",
      "step706:loss:5.561750411987305. time per iter: 64.05ms,tok/sec:1998.40,grad_norm:4.7149 \n",
      "step707:loss:6.125714302062988. time per iter: 57.90ms,tok/sec:2210.86,grad_norm:4.4211 \n",
      "step708:loss:6.9693779945373535. time per iter: 58.00ms,tok/sec:2206.92,grad_norm:4.5124 \n",
      "step709:loss:5.3467254638671875. time per iter: 68.89ms,tok/sec:1858.13,grad_norm:4.7770 \n",
      "step710:loss:5.93458366394043. time per iter: 64.33ms,tok/sec:1989.60,grad_norm:4.5141 \n",
      "step711:loss:6.320991039276123. time per iter: 54.29ms,tok/sec:2357.51,grad_norm:4.9888 \n",
      "step712:loss:6.182272911071777. time per iter: 60.83ms,tok/sec:2104.11,grad_norm:4.6006 \n",
      "step713:loss:6.614269256591797. time per iter: 62.13ms,tok/sec:2060.26,grad_norm:4.0630 \n",
      "step714:loss:5.819917678833008. time per iter: 48.40ms,tok/sec:2644.57,grad_norm:5.4022 \n",
      "step715:loss:5.0354108810424805. time per iter: 56.19ms,tok/sec:2277.83,grad_norm:7.4091 \n",
      "step716:loss:5.850109577178955. time per iter: 55.86ms,tok/sec:2291.33,grad_norm:5.2033 \n",
      "step717:loss:6.4064860343933105. time per iter: 54.66ms,tok/sec:2341.91,grad_norm:4.0338 \n",
      "step718:loss:6.1783833503723145. time per iter: 54.26ms,tok/sec:2359.13,grad_norm:4.5993 \n",
      "step719:loss:5.218716621398926. time per iter: 62.94ms,tok/sec:2033.68,grad_norm:5.2706 \n",
      "step720:loss:4.770597457885742. time per iter: 54.84ms,tok/sec:2334.21,grad_norm:5.0178 \n",
      "step721:loss:5.414237022399902. time per iter: 54.80ms,tok/sec:2335.60,grad_norm:6.5502 \n",
      "step722:loss:5.580001354217529. time per iter: 55.19ms,tok/sec:2319.10,grad_norm:7.5845 \n",
      "step723:loss:5.410589218139648. time per iter: 57.10ms,tok/sec:2241.78,grad_norm:6.1636 \n",
      "step724:loss:6.083292007446289. time per iter: 53.47ms,tok/sec:2393.74,grad_norm:5.0137 \n",
      "step725:loss:5.973287105560303. time per iter: 54.78ms,tok/sec:2336.50,grad_norm:4.4837 \n",
      "step726:loss:6.232806205749512. time per iter: 56.97ms,tok/sec:2246.94,grad_norm:4.3447 \n",
      "step727:loss:5.9922099113464355. time per iter: 52.17ms,tok/sec:2453.41,grad_norm:8.2729 \n",
      "step728:loss:6.617003917694092. time per iter: 55.65ms,tok/sec:2300.15,grad_norm:7.2030 \n",
      "step729:loss:6.151687145233154. time per iter: 53.42ms,tok/sec:2396.32,grad_norm:5.4011 \n",
      "step730:loss:5.311265468597412. time per iter: 66.10ms,tok/sec:1936.42,grad_norm:4.4528 \n",
      "step731:loss:5.08385705947876. time per iter: 55.95ms,tok/sec:2287.90,grad_norm:4.7091 \n",
      "step732:loss:5.666892051696777. time per iter: 53.64ms,tok/sec:2386.36,grad_norm:4.1409 \n",
      "step733:loss:5.827340602874756. time per iter: 55.77ms,tok/sec:2295.17,grad_norm:4.2715 \n",
      "step734:loss:5.9052205085754395. time per iter: 52.42ms,tok/sec:2441.63,grad_norm:4.4273 \n",
      "step735:loss:5.932555198669434. time per iter: 71.49ms,tok/sec:1790.42,grad_norm:4.1700 \n",
      "step736:loss:5.830076217651367. time per iter: 37.46ms,tok/sec:3416.62,grad_norm:4.2359 \n",
      "step737:loss:5.185155391693115. time per iter: 61.03ms,tok/sec:2097.46,grad_norm:5.3109 \n",
      "step738:loss:5.131550312042236. time per iter: 56.02ms,tok/sec:2284.87,grad_norm:4.3008 \n",
      "step739:loss:5.737841606140137. time per iter: 51.00ms,tok/sec:2509.97,grad_norm:4.7993 \n",
      "step740:loss:6.327347278594971. time per iter: 56.37ms,tok/sec:2270.67,grad_norm:4.5882 \n",
      "step741:loss:5.291553497314453. time per iter: 57.32ms,tok/sec:2233.14,grad_norm:4.4725 \n",
      "step742:loss:4.786203384399414. time per iter: 50.63ms,tok/sec:2528.05,grad_norm:5.0990 \n",
      "step743:loss:5.4850006103515625. time per iter: 46.81ms,tok/sec:2734.30,grad_norm:4.8467 \n",
      "step744:loss:5.336183547973633. time per iter: 47.81ms,tok/sec:2677.10,grad_norm:5.2050 \n",
      "step745:loss:6.18591833114624. time per iter: 48.64ms,tok/sec:2631.36,grad_norm:4.3771 \n",
      "step746:loss:6.12723970413208. time per iter: 54.70ms,tok/sec:2339.98,grad_norm:5.3056 \n",
      "step747:loss:6.215219974517822. time per iter: 51.31ms,tok/sec:2494.63,grad_norm:4.3480 \n",
      "step748:loss:5.863672256469727. time per iter: 47.62ms,tok/sec:2687.74,grad_norm:5.9824 \n",
      "step749:loss:6.54164981842041. time per iter: 48.24ms,tok/sec:2653.60,grad_norm:5.0498 \n",
      "step750:loss:6.137319564819336. time per iter: 50.46ms,tok/sec:2536.85,grad_norm:4.8077 \n",
      "step751:loss:5.852464199066162. time per iter: 49.18ms,tok/sec:2602.47,grad_norm:4.7536 \n",
      "step752:loss:6.277597904205322. time per iter: 51.02ms,tok/sec:2508.82,grad_norm:4.4534 \n",
      "step753:loss:6.273556232452393. time per iter: 48.59ms,tok/sec:2634.51,grad_norm:4.4227 \n",
      "step754:loss:6.331796646118164. time per iter: 53.90ms,tok/sec:2374.83,grad_norm:4.8194 \n",
      "step755:loss:5.889496803283691. time per iter: 58.14ms,tok/sec:2201.70,grad_norm:4.0878 \n",
      "step756:loss:6.438453197479248. time per iter: 59.85ms,tok/sec:2138.57,grad_norm:3.9644 \n",
      "step757:loss:6.520017147064209. time per iter: 55.43ms,tok/sec:2309.38,grad_norm:3.9708 \n",
      "step758:loss:5.403896808624268. time per iter: 60.77ms,tok/sec:2106.19,grad_norm:4.4914 \n",
      "step759:loss:6.413812160491943. time per iter: 53.44ms,tok/sec:2395.05,grad_norm:4.8912 \n",
      "step760:loss:6.209114074707031. time per iter: 44.63ms,tok/sec:2867.92,grad_norm:4.5085 \n",
      "step761:loss:6.019138336181641. time per iter: 48.60ms,tok/sec:2633.90,grad_norm:4.3000 \n",
      "step762:loss:6.210522651672363. time per iter: 48.42ms,tok/sec:2643.51,grad_norm:5.5785 \n",
      "step763:loss:5.341251850128174. time per iter: 45.98ms,tok/sec:2783.62,grad_norm:4.8236 \n",
      "step764:loss:6.233617782592773. time per iter: 47.80ms,tok/sec:2677.65,grad_norm:4.4381 \n",
      "step765:loss:5.95057487487793. time per iter: 46.15ms,tok/sec:2773.57,grad_norm:5.6166 \n",
      "step766:loss:6.523008346557617. time per iter: 52.93ms,tok/sec:2418.33,grad_norm:4.7405 \n",
      "step767:loss:6.237200736999512. time per iter: 48.90ms,tok/sec:2617.75,grad_norm:4.6629 \n",
      "step768:loss:6.139248847961426. time per iter: 55.24ms,tok/sec:2317.37,grad_norm:5.8005 \n",
      "step769:loss:6.323135852813721. time per iter: 58.49ms,tok/sec:2188.26,grad_norm:4.4599 \n",
      "step770:loss:5.959251403808594. time per iter: 44.41ms,tok/sec:2882.31,grad_norm:4.9664 \n",
      "step771:loss:6.234969615936279. time per iter: 40.60ms,tok/sec:3153.02,grad_norm:4.6591 \n",
      "step772:loss:6.193007469177246. time per iter: 53.31ms,tok/sec:2401.15,grad_norm:4.5590 \n",
      "step773:loss:6.344452857971191. time per iter: 49.92ms,tok/sec:2564.04,grad_norm:4.3413 \n",
      "step774:loss:6.404755592346191. time per iter: 50.03ms,tok/sec:2558.38,grad_norm:4.3901 \n",
      "step775:loss:6.059001445770264. time per iter: 48.07ms,tok/sec:2662.51,grad_norm:4.6441 \n",
      "step776:loss:5.751186847686768. time per iter: 54.25ms,tok/sec:2359.25,grad_norm:4.8255 \n",
      "step777:loss:5.651648998260498. time per iter: 56.12ms,tok/sec:2280.76,grad_norm:4.4837 \n",
      "step778:loss:5.860863208770752. time per iter: 60.81ms,tok/sec:2105.05,grad_norm:5.0146 \n",
      "step779:loss:5.902078628540039. time per iter: 56.53ms,tok/sec:2264.44,grad_norm:4.2323 \n",
      "step780:loss:5.711732387542725. time per iter: 61.49ms,tok/sec:2081.55,grad_norm:5.2095 \n",
      "step781:loss:5.8349456787109375. time per iter: 55.42ms,tok/sec:2309.69,grad_norm:4.7898 \n",
      "step782:loss:6.159491539001465. time per iter: 62.66ms,tok/sec:2042.92,grad_norm:4.0827 \n",
      "step783:loss:6.510493755340576. time per iter: 50.48ms,tok/sec:2535.66,grad_norm:5.6449 \n",
      "step784:loss:6.556197643280029. time per iter: 48.29ms,tok/sec:2650.60,grad_norm:5.0538 \n",
      "step785:loss:5.827832221984863. time per iter: 50.20ms,tok/sec:2549.77,grad_norm:5.3095 \n",
      "step786:loss:5.618653297424316. time per iter: 47.90ms,tok/sec:2672.04,grad_norm:5.2033 \n",
      "step787:loss:6.046655178070068. time per iter: 51.91ms,tok/sec:2465.67,grad_norm:5.7413 \n",
      "step788:loss:6.882164478302002. time per iter: 50.76ms,tok/sec:2521.85,grad_norm:4.5514 \n",
      "step789:loss:6.236495018005371. time per iter: 68.65ms,tok/sec:1864.65,grad_norm:4.9228 \n",
      "step790:loss:5.9567461013793945. time per iter: 74.79ms,tok/sec:1711.39,grad_norm:3.9989 \n",
      "step791:loss:6.293234825134277. time per iter: 61.66ms,tok/sec:2075.75,grad_norm:4.4919 \n",
      "step792:loss:5.862725734710693. time per iter: 56.12ms,tok/sec:2280.93,grad_norm:5.0084 \n",
      "step793:loss:6.541306495666504. time per iter: 53.18ms,tok/sec:2407.14,grad_norm:4.6827 \n",
      "step794:loss:5.4647603034973145. time per iter: 47.71ms,tok/sec:2682.95,grad_norm:5.0883 \n",
      "step795:loss:5.884349822998047. time per iter: 48.81ms,tok/sec:2622.27,grad_norm:4.7817 \n",
      "step796:loss:5.784760475158691. time per iter: 48.90ms,tok/sec:2617.57,grad_norm:5.6832 \n",
      "step797:loss:5.999402046203613. time per iter: 50.98ms,tok/sec:2510.94,grad_norm:4.7348 \n",
      "step798:loss:5.505084991455078. time per iter: 52.79ms,tok/sec:2424.54,grad_norm:4.4748 \n",
      "step799:loss:5.832228183746338. time per iter: 51.89ms,tok/sec:2466.91,grad_norm:3.9757 \n",
      "step800:loss:5.21008825302124. time per iter: 52.15ms,tok/sec:2454.33,grad_norm:5.3615 \n",
      "step801:loss:5.322803974151611. time per iter: 52.27ms,tok/sec:2448.99,grad_norm:5.7629 \n",
      "step802:loss:5.7965240478515625. time per iter: 48.85ms,tok/sec:2620.49,grad_norm:5.4637 \n",
      "step803:loss:6.0610809326171875. time per iter: 47.13ms,tok/sec:2715.94,grad_norm:5.8601 \n",
      "step804:loss:6.439713954925537. time per iter: 48.11ms,tok/sec:2660.53,grad_norm:4.5370 \n",
      "step805:loss:6.223142623901367. time per iter: 51.92ms,tok/sec:2465.21,grad_norm:5.1463 \n",
      "step806:loss:5.437447547912598. time per iter: 55.45ms,tok/sec:2308.32,grad_norm:4.7093 \n",
      "step807:loss:5.428900241851807. time per iter: 46.23ms,tok/sec:2768.95,grad_norm:4.4630 \n",
      "step808:loss:6.01132345199585. time per iter: 51.26ms,tok/sec:2497.21,grad_norm:4.3607 \n",
      "step809:loss:5.949281215667725. time per iter: 54.45ms,tok/sec:2350.95,grad_norm:4.5226 \n",
      "step810:loss:6.198894500732422. time per iter: 50.95ms,tok/sec:2512.26,grad_norm:4.3522 \n",
      "step811:loss:5.9295759201049805. time per iter: 46.82ms,tok/sec:2733.73,grad_norm:3.9767 \n",
      "step812:loss:5.302177906036377. time per iter: 44.95ms,tok/sec:2847.49,grad_norm:5.9293 \n",
      "step813:loss:5.637493133544922. time per iter: 47.66ms,tok/sec:2685.71,grad_norm:4.5252 \n",
      "step814:loss:6.429676055908203. time per iter: 55.78ms,tok/sec:2294.70,grad_norm:4.5018 \n",
      "step815:loss:6.498891830444336. time per iter: 52.74ms,tok/sec:2426.92,grad_norm:4.4145 \n",
      "step816:loss:6.758784294128418. time per iter: 58.10ms,tok/sec:2203.12,grad_norm:4.8801 \n",
      "step817:loss:6.376243591308594. time per iter: 47.74ms,tok/sec:2681.42,grad_norm:5.4135 \n",
      "step818:loss:6.484121322631836. time per iter: 53.20ms,tok/sec:2405.84,grad_norm:5.1326 \n",
      "step819:loss:6.2165679931640625. time per iter: 52.92ms,tok/sec:2418.88,grad_norm:4.4660 \n",
      "step820:loss:6.034082412719727. time per iter: 49.23ms,tok/sec:2600.05,grad_norm:5.0972 \n",
      "step821:loss:5.347084045410156. time per iter: 52.78ms,tok/sec:2424.99,grad_norm:5.7477 \n",
      "step822:loss:4.77333927154541. time per iter: 46.16ms,tok/sec:2773.21,grad_norm:5.4633 \n",
      "step823:loss:6.287334442138672. time per iter: 55.83ms,tok/sec:2292.53,grad_norm:4.7044 \n",
      "step824:loss:5.921816825866699. time per iter: 58.82ms,tok/sec:2176.32,grad_norm:4.5826 \n",
      "step825:loss:5.8845744132995605. time per iter: 46.22ms,tok/sec:2769.15,grad_norm:4.9269 \n",
      "step826:loss:6.1370015144348145. time per iter: 51.74ms,tok/sec:2474.11,grad_norm:4.6287 \n",
      "step827:loss:4.871227264404297. time per iter: 43.83ms,tok/sec:2920.09,grad_norm:4.4959 \n",
      "step828:loss:5.24757194519043. time per iter: 43.38ms,tok/sec:2950.93,grad_norm:4.4758 \n",
      "step829:loss:6.209731578826904. time per iter: 53.21ms,tok/sec:2405.38,grad_norm:4.7497 \n",
      "step830:loss:6.199796199798584. time per iter: 55.39ms,tok/sec:2311.03,grad_norm:4.6184 \n",
      "step831:loss:5.1750569343566895. time per iter: 52.84ms,tok/sec:2422.36,grad_norm:4.6715 \n",
      "step832:loss:5.8571672439575195. time per iter: 46.85ms,tok/sec:2732.26,grad_norm:5.2366 \n",
      "step833:loss:6.31467342376709. time per iter: 51.36ms,tok/sec:2492.19,grad_norm:4.4987 \n",
      "step834:loss:5.260858058929443. time per iter: 52.16ms,tok/sec:2453.99,grad_norm:4.7554 \n",
      "step835:loss:5.610699653625488. time per iter: 62.87ms,tok/sec:2036.09,grad_norm:4.6892 \n",
      "step836:loss:5.835149765014648. time per iter: 51.06ms,tok/sec:2506.89,grad_norm:4.9897 \n",
      "step837:loss:5.933954238891602. time per iter: 68.70ms,tok/sec:1863.25,grad_norm:4.2842 \n",
      "step838:loss:6.070223331451416. time per iter: 52.37ms,tok/sec:2443.93,grad_norm:4.9348 \n",
      "step839:loss:6.286264419555664. time per iter: 52.82ms,tok/sec:2423.12,grad_norm:4.8942 \n",
      "step840:loss:6.053455352783203. time per iter: 55.10ms,tok/sec:2323.01,grad_norm:5.2724 \n",
      "step841:loss:5.916967391967773. time per iter: 44.94ms,tok/sec:2848.54,grad_norm:4.6190 \n",
      "step842:loss:7.018350601196289. time per iter: 51.70ms,tok/sec:2475.91,grad_norm:6.4897 \n",
      "step843:loss:6.359193801879883. time per iter: 49.68ms,tok/sec:2576.48,grad_norm:5.2907 \n",
      "step844:loss:5.754452705383301. time per iter: 55.28ms,tok/sec:2315.54,grad_norm:6.1206 \n",
      "step845:loss:6.542424201965332. time per iter: 51.72ms,tok/sec:2474.73,grad_norm:4.8841 \n",
      "step846:loss:5.897724628448486. time per iter: 56.89ms,tok/sec:2249.97,grad_norm:5.9823 \n",
      "step847:loss:5.8507208824157715. time per iter: 53.30ms,tok/sec:2401.49,grad_norm:4.6659 \n",
      "step848:loss:5.773016929626465. time per iter: 55.62ms,tok/sec:2301.31,grad_norm:5.3416 \n",
      "step849:loss:5.9692559242248535. time per iter: 53.34ms,tok/sec:2399.76,grad_norm:4.6017 \n",
      "step850:loss:5.856674671173096. time per iter: 48.54ms,tok/sec:2636.99,grad_norm:4.7289 \n",
      "step851:loss:5.481828689575195. time per iter: 55.05ms,tok/sec:2325.31,grad_norm:4.6009 \n",
      "step852:loss:5.409043788909912. time per iter: 52.16ms,tok/sec:2454.11,grad_norm:4.6291 \n",
      "step853:loss:5.425983428955078. time per iter: 52.68ms,tok/sec:2429.69,grad_norm:4.4015 \n",
      "step854:loss:5.674013137817383. time per iter: 54.85ms,tok/sec:2333.67,grad_norm:4.7597 \n",
      "step855:loss:6.000279903411865. time per iter: 48.59ms,tok/sec:2634.37,grad_norm:4.3860 \n",
      "step856:loss:5.664285182952881. time per iter: 50.39ms,tok/sec:2540.01,grad_norm:4.3023 \n",
      "step857:loss:5.898312568664551. time per iter: 53.23ms,tok/sec:2404.53,grad_norm:4.5410 \n",
      "step858:loss:6.199309825897217. time per iter: 53.61ms,tok/sec:2387.68,grad_norm:4.2353 \n",
      "step859:loss:5.522255897521973. time per iter: 52.69ms,tok/sec:2429.24,grad_norm:6.4934 \n",
      "step860:loss:6.466434001922607. time per iter: 46.87ms,tok/sec:2730.86,grad_norm:4.7957 \n",
      "step861:loss:5.269601821899414. time per iter: 53.78ms,tok/sec:2380.02,grad_norm:7.3459 \n",
      "step862:loss:5.72067928314209. time per iter: 46.26ms,tok/sec:2766.69,grad_norm:7.5631 \n",
      "step863:loss:5.333138465881348. time per iter: 50.30ms,tok/sec:2544.79,grad_norm:6.4734 \n",
      "step864:loss:5.814237117767334. time per iter: 48.15ms,tok/sec:2658.62,grad_norm:5.2490 \n",
      "step865:loss:5.711023330688477. time per iter: 45.04ms,tok/sec:2842.11,grad_norm:5.2229 \n",
      "step866:loss:5.685475826263428. time per iter: 51.05ms,tok/sec:2507.47,grad_norm:4.2300 \n",
      "step867:loss:4.834208011627197. time per iter: 50.87ms,tok/sec:2516.24,grad_norm:5.6120 \n",
      "step868:loss:5.004641056060791. time per iter: 49.81ms,tok/sec:2569.83,grad_norm:4.8622 \n",
      "step869:loss:6.302924156188965. time per iter: 49.75ms,tok/sec:2572.98,grad_norm:5.8314 \n",
      "step870:loss:5.63446044921875. time per iter: 50.57ms,tok/sec:2530.97,grad_norm:5.7783 \n",
      "step871:loss:5.0163116455078125. time per iter: 49.50ms,tok/sec:2585.98,grad_norm:5.0531 \n",
      "step872:loss:6.071399211883545. time per iter: 48.43ms,tok/sec:2642.85,grad_norm:5.6748 \n",
      "step873:loss:5.896620750427246. time per iter: 48.32ms,tok/sec:2649.25,grad_norm:4.9958 \n",
      "step874:loss:5.2592644691467285. time per iter: 49.16ms,tok/sec:2603.89,grad_norm:6.4237 \n",
      "step875:loss:5.306386947631836. time per iter: 52.01ms,tok/sec:2461.18,grad_norm:5.0388 \n",
      "step876:loss:5.4501848220825195. time per iter: 58.96ms,tok/sec:2170.87,grad_norm:5.4926 \n",
      "step877:loss:5.555056571960449. time per iter: 54.52ms,tok/sec:2347.58,grad_norm:4.6923 \n",
      "step878:loss:6.145119667053223. time per iter: 51.71ms,tok/sec:2475.28,grad_norm:6.3942 \n",
      "step879:loss:6.20033597946167. time per iter: 53.36ms,tok/sec:2398.89,grad_norm:4.9929 \n",
      "step880:loss:5.628286838531494. time per iter: 51.76ms,tok/sec:2472.83,grad_norm:4.5983 \n",
      "step881:loss:5.979189872741699. time per iter: 56.03ms,tok/sec:2284.68,grad_norm:4.1832 \n",
      "step882:loss:5.708034038543701. time per iter: 52.34ms,tok/sec:2445.32,grad_norm:4.4181 \n",
      "step883:loss:4.948278427124023. time per iter: 56.69ms,tok/sec:2257.83,grad_norm:7.6309 \n",
      "step884:loss:5.45358419418335. time per iter: 44.42ms,tok/sec:2881.71,grad_norm:6.6304 \n",
      "step885:loss:6.107731819152832. time per iter: 56.71ms,tok/sec:2257.22,grad_norm:4.3615 \n",
      "step886:loss:6.69171142578125. time per iter: 53.96ms,tok/sec:2372.05,grad_norm:4.1105 \n",
      "step887:loss:5.633780002593994. time per iter: 57.95ms,tok/sec:2208.78,grad_norm:5.2610 \n",
      "step888:loss:6.761351108551025. time per iter: 46.75ms,tok/sec:2737.81,grad_norm:4.5031 \n",
      "step889:loss:6.417065620422363. time per iter: 47.27ms,tok/sec:2708.09,grad_norm:5.6277 \n",
      "step890:loss:6.052740573883057. time per iter: 50.04ms,tok/sec:2558.10,grad_norm:5.0325 \n",
      "step891:loss:5.343056678771973. time per iter: 54.17ms,tok/sec:2363.11,grad_norm:5.8838 \n",
      "step892:loss:5.421257495880127. time per iter: 52.79ms,tok/sec:2424.60,grad_norm:5.4825 \n",
      "step893:loss:5.876623153686523. time per iter: 54.89ms,tok/sec:2332.11,grad_norm:5.9803 \n",
      "step894:loss:6.0995354652404785. time per iter: 42.70ms,tok/sec:2997.32,grad_norm:5.0873 \n",
      "step895:loss:7.078178405761719. time per iter: 52.07ms,tok/sec:2458.39,grad_norm:5.3739 \n",
      "step896:loss:6.081836700439453. time per iter: 51.16ms,tok/sec:2501.82,grad_norm:5.3447 \n",
      "step897:loss:6.181213855743408. time per iter: 55.49ms,tok/sec:2306.60,grad_norm:5.5435 \n",
      "step898:loss:5.775201797485352. time per iter: 51.27ms,tok/sec:2496.78,grad_norm:7.1499 \n",
      "step899:loss:5.898271560668945. time per iter: 51.72ms,tok/sec:2474.86,grad_norm:4.5983 \n",
      "step900:loss:6.127693176269531. time per iter: 50.49ms,tok/sec:2534.97,grad_norm:4.1225 \n",
      "step901:loss:6.294036865234375. time per iter: 47.19ms,tok/sec:2712.28,grad_norm:4.7535 \n",
      "step902:loss:5.648947715759277. time per iter: 56.83ms,tok/sec:2252.51,grad_norm:4.6812 \n",
      "step903:loss:5.749476909637451. time per iter: 53.65ms,tok/sec:2385.99,grad_norm:4.3431 \n",
      "step904:loss:5.424927711486816. time per iter: 50.24ms,tok/sec:2547.79,grad_norm:3.8701 \n",
      "step905:loss:5.407068252563477. time per iter: 52.77ms,tok/sec:2425.52,grad_norm:5.0162 \n",
      "step906:loss:5.359762668609619. time per iter: 52.36ms,tok/sec:2444.70,grad_norm:4.9595 \n",
      "step907:loss:5.224831581115723. time per iter: 52.33ms,tok/sec:2445.80,grad_norm:5.6420 \n",
      "step908:loss:4.614239692687988. time per iter: 48.04ms,tok/sec:2664.69,grad_norm:5.6396 \n",
      "step909:loss:5.372786521911621. time per iter: 50.22ms,tok/sec:2548.99,grad_norm:5.3864 \n",
      "step910:loss:6.222758769989014. time per iter: 68.08ms,tok/sec:1880.26,grad_norm:4.6360 \n",
      "step911:loss:6.493513107299805. time per iter: 55.12ms,tok/sec:2322.18,grad_norm:4.9965 \n",
      "step912:loss:6.025351524353027. time per iter: 54.49ms,tok/sec:2348.99,grad_norm:4.9636 \n",
      "step913:loss:5.41793155670166. time per iter: 47.14ms,tok/sec:2715.28,grad_norm:4.1901 \n",
      "step914:loss:6.109478950500488. time per iter: 51.38ms,tok/sec:2491.13,grad_norm:4.6447 \n",
      "step915:loss:6.58455228805542. time per iter: 53.61ms,tok/sec:2387.63,grad_norm:4.9936 \n",
      "step916:loss:6.0925493240356445. time per iter: 52.47ms,tok/sec:2439.65,grad_norm:5.5960 \n",
      "step917:loss:5.598179340362549. time per iter: 55.79ms,tok/sec:2294.49,grad_norm:4.7307 \n",
      "step918:loss:5.69427490234375. time per iter: 56.06ms,tok/sec:2283.09,grad_norm:4.8155 \n",
      "step919:loss:5.134880542755127. time per iter: 49.18ms,tok/sec:2602.52,grad_norm:5.4401 \n",
      "step920:loss:5.555777072906494. time per iter: 49.29ms,tok/sec:2596.94,grad_norm:4.6765 \n",
      "step921:loss:6.174941539764404. time per iter: 54.85ms,tok/sec:2333.83,grad_norm:4.7797 \n",
      "step922:loss:6.149234294891357. time per iter: 52.59ms,tok/sec:2433.70,grad_norm:5.2744 \n",
      "step923:loss:5.710249423980713. time per iter: 54.70ms,tok/sec:2339.83,grad_norm:5.0094 \n",
      "step924:loss:4.9232497215271. time per iter: 48.64ms,tok/sec:2631.67,grad_norm:5.9631 \n",
      "step925:loss:4.4576640129089355. time per iter: 49.38ms,tok/sec:2592.31,grad_norm:4.9484 \n",
      "step926:loss:4.952402591705322. time per iter: 62.49ms,tok/sec:2048.44,grad_norm:4.7345 \n",
      "step927:loss:4.485996723175049. time per iter: 50.17ms,tok/sec:2551.53,grad_norm:5.2876 \n",
      "step928:loss:5.253968238830566. time per iter: 54.51ms,tok/sec:2348.35,grad_norm:7.2972 \n",
      "step929:loss:5.009944915771484. time per iter: 50.41ms,tok/sec:2539.17,grad_norm:5.0727 \n",
      "step930:loss:6.533497333526611. time per iter: 58.48ms,tok/sec:2188.70,grad_norm:4.8537 \n",
      "step931:loss:6.456430435180664. time per iter: 54.63ms,tok/sec:2343.24,grad_norm:4.6831 \n",
      "step932:loss:6.268412113189697. time per iter: 56.56ms,tok/sec:2262.92,grad_norm:5.5103 \n",
      "step933:loss:6.410417556762695. time per iter: 52.23ms,tok/sec:2450.91,grad_norm:4.9835 \n",
      "step934:loss:5.674478530883789. time per iter: 59.48ms,tok/sec:2151.82,grad_norm:4.6757 \n",
      "step935:loss:6.1110076904296875. time per iter: 51.05ms,tok/sec:2507.58,grad_norm:5.3441 \n",
      "step936:loss:5.673779010772705. time per iter: 47.06ms,tok/sec:2719.93,grad_norm:4.2561 \n",
      "step937:loss:5.762787818908691. time per iter: 53.18ms,tok/sec:2406.90,grad_norm:5.7138 \n",
      "step938:loss:5.319159507751465. time per iter: 49.70ms,tok/sec:2575.50,grad_norm:4.4206 \n",
      "step939:loss:5.439326763153076. time per iter: 59.36ms,tok/sec:2156.32,grad_norm:5.0960 \n",
      "step940:loss:5.644286155700684. time per iter: 65.82ms,tok/sec:1944.63,grad_norm:5.2537 \n",
      "step941:loss:5.1654767990112305. time per iter: 50.56ms,tok/sec:2531.60,grad_norm:5.3506 \n",
      "step942:loss:5.490162372589111. time per iter: 45.56ms,tok/sec:2809.42,grad_norm:4.7503 \n",
      "step943:loss:5.007574081420898. time per iter: 55.95ms,tok/sec:2287.86,grad_norm:6.2876 \n",
      "step944:loss:5.634270191192627. time per iter: 60.08ms,tok/sec:2130.39,grad_norm:4.4667 \n",
      "step945:loss:5.313882827758789. time per iter: 56.26ms,tok/sec:2275.15,grad_norm:5.2801 \n",
      "step946:loss:5.85198450088501. time per iter: 58.37ms,tok/sec:2192.88,grad_norm:5.9860 \n",
      "step947:loss:5.552592754364014. time per iter: 56.17ms,tok/sec:2278.94,grad_norm:6.5398 \n",
      "step948:loss:5.665142059326172. time per iter: 61.96ms,tok/sec:2065.70,grad_norm:5.8651 \n",
      "step949:loss:5.239614963531494. time per iter: 59.63ms,tok/sec:2146.75,grad_norm:6.4828 \n",
      "step950:loss:5.582560062408447. time per iter: 57.04ms,tok/sec:2244.01,grad_norm:5.2574 \n",
      "step951:loss:6.043168067932129. time per iter: 60.49ms,tok/sec:2116.20,grad_norm:6.7368 \n",
      "step952:loss:5.833693504333496. time per iter: 55.58ms,tok/sec:2302.98,grad_norm:5.3039 \n",
      "step953:loss:6.0620951652526855. time per iter: 51.83ms,tok/sec:2469.51,grad_norm:4.2985 \n",
      "step954:loss:5.281372547149658. time per iter: 46.43ms,tok/sec:2756.83,grad_norm:4.9715 \n",
      "step955:loss:4.792995452880859. time per iter: 52.88ms,tok/sec:2420.44,grad_norm:4.7422 \n",
      "step956:loss:6.388584613800049. time per iter: 57.29ms,tok/sec:2234.06,grad_norm:6.5886 \n",
      "step957:loss:4.9024529457092285. time per iter: 51.36ms,tok/sec:2491.99,grad_norm:5.5093 \n",
      "step958:loss:4.878722190856934. time per iter: 59.31ms,tok/sec:2158.11,grad_norm:5.5739 \n",
      "step959:loss:4.560606002807617. time per iter: 55.82ms,tok/sec:2292.95,grad_norm:12.7115 \n",
      "step960:loss:5.840144157409668. time per iter: 57.32ms,tok/sec:2232.93,grad_norm:5.1949 \n",
      "step961:loss:5.809446334838867. time per iter: 59.86ms,tok/sec:2138.49,grad_norm:4.6338 \n",
      "step962:loss:5.964658260345459. time per iter: 59.13ms,tok/sec:2164.71,grad_norm:4.2617 \n",
      "step963:loss:5.550944805145264. time per iter: 54.77ms,tok/sec:2336.91,grad_norm:5.0328 \n",
      "step964:loss:5.136780261993408. time per iter: 55.63ms,tok/sec:2300.92,grad_norm:5.4609 \n",
      "step965:loss:5.529950141906738. time per iter: 52.56ms,tok/sec:2435.33,grad_norm:4.7539 \n",
      "step966:loss:4.3813910484313965. time per iter: 54.72ms,tok/sec:2339.07,grad_norm:6.5448 \n",
      "step967:loss:5.645625591278076. time per iter: 50.49ms,tok/sec:2535.02,grad_norm:4.7413 \n",
      "step968:loss:5.287004470825195. time per iter: 55.85ms,tok/sec:2292.06,grad_norm:4.7032 \n",
      "step969:loss:5.642172336578369. time per iter: 58.69ms,tok/sec:2180.85,grad_norm:4.5091 \n",
      "step970:loss:3.7678213119506836. time per iter: 55.74ms,tok/sec:2296.43,grad_norm:5.4834 \n",
      "step971:loss:3.078320264816284. time per iter: 57.22ms,tok/sec:2236.89,grad_norm:5.9904 \n",
      "step972:loss:5.402946949005127. time per iter: 51.93ms,tok/sec:2465.04,grad_norm:5.1696 \n",
      "step973:loss:5.863104820251465. time per iter: 55.18ms,tok/sec:2319.67,grad_norm:4.2678 \n",
      "step974:loss:5.749836444854736. time per iter: 59.53ms,tok/sec:2150.21,grad_norm:5.4080 \n",
      "step975:loss:5.845393180847168. time per iter: 67.40ms,tok/sec:1899.23,grad_norm:4.9631 \n",
      "step976:loss:5.598407745361328. time per iter: 49.81ms,tok/sec:2569.76,grad_norm:4.8991 \n",
      "step977:loss:5.944568634033203. time per iter: 59.48ms,tok/sec:2152.08,grad_norm:4.4977 \n",
      "step978:loss:5.4287800788879395. time per iter: 56.27ms,tok/sec:2274.58,grad_norm:5.0346 \n",
      "step979:loss:6.129161357879639. time per iter: 56.41ms,tok/sec:2269.16,grad_norm:4.8442 \n",
      "step980:loss:5.235386848449707. time per iter: 56.96ms,tok/sec:2247.38,grad_norm:4.8764 \n",
      "step981:loss:5.159865856170654. time per iter: 53.35ms,tok/sec:2399.06,grad_norm:4.8020 \n",
      "step982:loss:4.7128071784973145. time per iter: 57.08ms,tok/sec:2242.30,grad_norm:4.7897 \n",
      "step983:loss:5.136537551879883. time per iter: 52.13ms,tok/sec:2455.30,grad_norm:4.4446 \n",
      "step984:loss:4.890798568725586. time per iter: 54.79ms,tok/sec:2336.30,grad_norm:5.5999 \n",
      "step985:loss:6.043762683868408. time per iter: 46.06ms,tok/sec:2779.14,grad_norm:4.7321 \n",
      "step986:loss:5.750201225280762. time per iter: 52.90ms,tok/sec:2419.78,grad_norm:4.4552 \n",
      "step987:loss:6.129247188568115. time per iter: 68.64ms,tok/sec:1864.79,grad_norm:4.9143 \n",
      "step988:loss:5.165297508239746. time per iter: 77.94ms,tok/sec:1642.38,grad_norm:6.0313 \n",
      "step989:loss:5.012605667114258. time per iter: 99.66ms,tok/sec:1284.32,grad_norm:5.8430 \n",
      "step990:loss:3.688410520553589. time per iter: 76.56ms,tok/sec:1671.93,grad_norm:6.6502 \n",
      "step991:loss:4.259316921234131. time per iter: 63.86ms,tok/sec:2004.30,grad_norm:6.1261 \n",
      "step992:loss:4.410885810852051. time per iter: 49.88ms,tok/sec:2566.34,grad_norm:6.2154 \n",
      "step993:loss:3.8947014808654785. time per iter: 58.65ms,tok/sec:2182.34,grad_norm:5.4548 \n",
      "step994:loss:4.086810111999512. time per iter: 44.74ms,tok/sec:2861.21,grad_norm:5.5652 \n",
      "step995:loss:5.042861461639404. time per iter: 55.71ms,tok/sec:2297.45,grad_norm:6.0604 \n",
      "step996:loss:4.687385559082031. time per iter: 51.42ms,tok/sec:2489.46,grad_norm:5.2230 \n",
      "step997:loss:4.611475467681885. time per iter: 44.56ms,tok/sec:2872.46,grad_norm:3.9635 \n",
      "step998:loss:5.205106735229492. time per iter: 59.56ms,tok/sec:2149.13,grad_norm:5.0313 \n",
      "step999:loss:5.235579013824463. time per iter: 54.23ms,tok/sec:2360.12,grad_norm:4.9008 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = GPT(GPTConfig())\n",
    "model.train()\n",
    "model.to(device)\n",
    "# only work in ubuntu linux\n",
    "#model = torch.compile(model) # makes your model run faster by compiling it, instead of interpreting it op-by-op in Python\n",
    "\n",
    "train_loader = DataLoaderLite(B=4,T=32)\n",
    "val_loader = DataLoaderLite(B=4,T=32,split='val')\n",
    "torch.set_float32_matmul_precision('high') #default is highest\n",
    "# optimizer = torch.optim.AdamW(model.parameters(),lr=3e-4,betas = (0.9,0.95),eps=1e-8) #follow GPT3 hyperparameters\n",
    "optimizer = model.configure_optimizers(weight_decay=0.1,learning_rate=max_lr,device_type=device)\n",
    "for step in range(1000):\n",
    "    t0 = time.time()\n",
    "    x,y = train_loader.next_batch()\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    with torch.autocast(device_type=device, dtype=torch.float16):\n",
    "        logits,loss = model(x,y)\n",
    "    # default dtype is float32 - may not be too efficient -switch to float16\n",
    "    loss.backward()\n",
    "    norm = torch.nn.utils.clip_grad_norm_(model.parameters(),1.0) #clip the gradient to 1.0\n",
    "    # prevent the gradient from exploding\n",
    "    # determine annd set the learning rate\n",
    "    lr = get_lr(step)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    optimizer.step()\n",
    "    torch.cuda.synchronize()\n",
    "    t1 = time.time()\n",
    "    print(f\"step{step}:loss:{loss.item()}. time per iter: {(t1 - t0)*1000:.2f}ms,tok/sec:{(x.shape[0]*x.shape[1])/(t1 - t0):.2f},grad_norm:{norm:.4f} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a6b22c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss:5.939044952392578\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    x,y = val_loader.next_batch()\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    logits,loss = model(x,y)\n",
    "    print(f\"val loss:{loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00e3c8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Hello, I'm a language model,\n",
      "And that in a love the hand upon in thy mind,\n",
      "He would a good to thy face.\n",
      "> Hello, I'm a language model,\n",
      "Where by the face, my take, I could you have the one:\n",
      "That must a name;\n",
      "> Hello, I'm a language model,\n",
      "And me be no must thee\n",
      "And my death, if that you have the Lord\n",
      "And as I\n",
      "> Hello, I'm a language model,\n",
      "Where here to the king.\n",
      "\n",
      "DUKE OF YORK:\n",
      "You do to one; I\n",
      "> Hello, I'm a language model,\n",
      "I have we is thou will would his man as a time.\n",
      "\n",
      "DUKE OF YORK:\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "num_return_sequences = 5\n",
    "max_length = 30\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "enc = tiktoken.get_encoding('gpt2')\n",
    "tokens = enc.encode(\"Hello, I'm a language model,\")\n",
    "tokens = torch.tensor(tokens, dtype=torch.long) # (8,)\n",
    "tokens = tokens.unsqueeze(0).repeat(num_return_sequences, 1) # (5, 8)\n",
    "x = tokens.to(device)\n",
    "# generate! right now x is (B, T) where B = 5, T = 8\n",
    "# set the seed to 42\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "while x.size(1) < max_length:\n",
    "    # forward the model to get the logits\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)[0] # (B, T, vocab_size)\n",
    "        # take the logits at the last position\n",
    "        logits = logits[:, -1, :] # (B, vocab_size)\n",
    "        # get the probabilities\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        # do top-k sampling of 50 (huggingface pipeline default)\n",
    "        # topk_probs here becomes (5, 50), topk_indices is (5, 50)\n",
    "        topk_probs, topk_indices = torch.topk(probs, 50, dim=-1)\n",
    "        # select a token from the top-k probabilities\n",
    "        # note: multinomial does not demand the input to sum to 1\n",
    "        ix = torch.multinomial(topk_probs, 1) # (B, 1)\n",
    "        # gather the corresponding indices\n",
    "        xcol = torch.gather(topk_indices, -1, ix) # (B, 1)\n",
    "        # append to the sequence\n",
    "        x = torch.cat((x, xcol), dim=1)\n",
    "\n",
    "# print the generated text\n",
    "for step in range(num_return_sequences):\n",
    "    tokens = x[step, :max_length].tolist()\n",
    "    decoded = enc.decode(tokens)\n",
    "    print(\">\", decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "788b1ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9850)\n"
     ]
    }
   ],
   "source": [
    "# standard deviation grows inside the residual connection stream\n",
    "x = torch.zeros(768)\n",
    "n = 100 # number of layers\n",
    "for step in range(n):\n",
    "    x = x + torch.randn(768)*(n**-0.5)\n",
    "\n",
    "print(x.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
